apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-05T14:25:22Z"
    generateName: fleet-agent-
    labels:
      app: fleet-agent
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: fleet-agent-6f4bc75f47
      statefulset.kubernetes.io/pod-name: fleet-agent-0
    name: fleet-agent-0
    namespace: cattle-fleet-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: fleet-agent
      uid: 72baacf5-a8af-4aac-a2ca-b3aa42483fcb
    resourceVersion: "128114"
    uid: a769e874-e1e1-42fb-a690-422f503b0902
  spec:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - preference:
            matchExpressions:
            - key: fleet.cattle.io/agent
              operator: In
              values:
              - "true"
          weight: 1
    containers:
    - command:
      - fleetagent
      env:
      - name: BUNDLEDEPLOYMENT_RECONCILER_WORKERS
        value: "50"
      - name: DRIFT_RECONCILER_WORKERS
        value: "50"
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: AGENT_SCOPE
      image: rancher/fleet-agent:v0.11.3
      imagePullPolicy: IfNotPresent
      name: fleet-agent
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /.kube
        name: kube
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9qsxv
        readOnly: true
    - command:
      - fleetagent
      - clusterstatus
      env:
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: CHECKIN_INTERVAL
        value: 15m0s
      image: rancher/fleet-agent:v0.11.3
      imagePullPolicy: IfNotPresent
      name: fleet-agent-clusterstatus
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9qsxv
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: fleet-agent-0
    initContainers:
    - command:
      - fleetagent
      - register
      env:
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/fleet-agent:v0.11.3
      imagePullPolicy: IfNotPresent
      name: fleet-agent-register
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9qsxv
        readOnly: true
    nodeName: ip-172-31-18-33
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsGroup: 1000
      runAsNonRoot: true
      runAsUser: 1000
    serviceAccount: fleet-agent
    serviceAccountName: fleet-agent
    subdomain: fleet-agent
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node.cloudprovider.kubernetes.io/uninitialized
      operator: Equal
      value: "true"
    - effect: NoSchedule
      key: cattle.io/os
      operator: Equal
      value: linux
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: kube
    - name: kube-api-access-9qsxv
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:08Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T14:25:22Z"
      message: 'containers with incomplete status: [fleet-agent-register]'
      reason: ContainersNotInitialized
      status: "False"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T14:25:22Z"
      message: 'containers with unready status: [fleet-agent fleet-agent-clusterstatus]'
      reason: ContainersNotReady
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T14:25:22Z"
      message: 'containers with unready status: [fleet-agent fleet-agent-clusterstatus]'
      reason: ContainersNotReady
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T14:25:22Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - image: rancher/fleet-agent:v0.11.3
      imageID: ""
      lastState: {}
      name: fleet-agent
      ready: false
      restartCount: 0
      started: false
      state:
        waiting:
          reason: PodInitializing
      volumeMounts:
      - mountPath: /.kube
        name: kube
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9qsxv
        readOnly: true
        recursiveReadOnly: Disabled
    - image: rancher/fleet-agent:v0.11.3
      imageID: ""
      lastState: {}
      name: fleet-agent-clusterstatus
      ready: false
      restartCount: 0
      started: false
      state:
        waiting:
          reason: PodInitializing
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9qsxv
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 172.31.18.33
    hostIPs:
    - ip: 172.31.18.33
    initContainerStatuses:
    - containerID: containerd://f95e3f780c797a1085f3f9efbd4d60718a09eaee6e2bbed21983970f051264b9
      image: docker.io/rancher/fleet-agent:v0.11.3
      imageID: docker.io/rancher/fleet-agent@sha256:2a229b1be5f095e5c56e06c51318cf6d0aeed19204fb3c97e15052bc92591d23
      lastState: {}
      name: fleet-agent-register
      ready: false
      restartCount: 35
      started: true
      state:
        running:
          startedAt: "2025-03-03T02:55:04Z"
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9qsxv
        readOnly: true
        recursiveReadOnly: Disabled
    phase: Pending
    podIP: 10.42.0.78
    podIPs:
    - ip: 10.42.0.78
    qosClass: BestEffort
    startTime: "2025-02-05T14:25:22Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-02-05T14:24:06Z"
    creationTimestamp: "2025-02-09T05:56:45Z"
    generateName: cattle-cluster-agent-55dd5f54bb-
    labels:
      app: cattle-cluster-agent
      pod-template-hash: 55dd5f54bb
    name: cattle-cluster-agent-55dd5f54bb-pbm67
    namespace: cattle-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: cattle-cluster-agent-55dd5f54bb
      uid: 2bb122d9-06a2-49f2-96fe-f264fc401428
    resourceVersion: "128362"
    uid: 8dc4bbf4-80d6-4bcf-af2a-88a41017a4e7
  spec:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - preference:
            matchExpressions:
            - key: node-role.kubernetes.io/controlplane
              operator: In
              values:
              - "true"
          weight: 100
        - preference:
            matchExpressions:
            - key: node-role.kubernetes.io/control-plane
              operator: In
              values:
              - "true"
          weight: 100
        - preference:
            matchExpressions:
            - key: node-role.kubernetes.io/master
              operator: In
              values:
              - "true"
          weight: 100
        - preference:
            matchExpressions:
            - key: cattle.io/cluster-agent
              operator: In
              values:
              - "true"
          weight: 1
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: beta.kubernetes.io/os
              operator: NotIn
              values:
              - windows
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - cattle-cluster-agent
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - env:
      - name: CATTLE_FEATURES
        value: embedded-cluster-api=false,fleet=false,managed-system-upgrade-controller=true,multi-cluster-management=false,multi-cluster-management-agent=true,provisioningprebootstrap=false,provisioningv2=false,rke2=false,ui-sql-cache=false
      - name: CATTLE_IS_RKE
        value: "false"
      - name: CATTLE_SERVER
        value: https://44.220.0.65.sslip.io
      - name: CATTLE_CA_CHECKSUM
      - name: CATTLE_CLUSTER
        value: "true"
      - name: CATTLE_K8S_MANAGED
        value: "true"
      - name: CATTLE_CLUSTER_REGISTRY
      - name: CATTLE_SERVER_VERSION
        value: v2.10.2
      - name: CATTLE_INSTALL_UUID
        value: dd7c2187-12b9-4774-8ac3-7ac6e676ed0b
      - name: CATTLE_INGRESS_IP_DOMAIN
        value: sslip.io
      - name: STRICT_VERIFY
        value: "false"
      image: rancher/rancher-agent:v2.10.2
      imagePullPolicy: IfNotPresent
      name: cluster-register
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /cattle-credentials
        name: cattle-credentials
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dc66c
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: ip-172-31-18-33
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: cattle
    serviceAccountName: cattle
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/controlplane
      value: "true"
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: cattle-credentials
      secret:
        defaultMode: 320
        secretName: cattle-credentials-8271d07
    - name: kube-api-access-dc66c
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:06Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-09T05:56:45Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:56:42Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:56:42Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-09T05:56:45Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://57ea8e1ebda4f82d23facd4c06525d1deb9fc78222d91b936787b5fa593e1477
      image: docker.io/rancher/rancher-agent:v2.10.2
      imageID: docker.io/rancher/rancher-agent@sha256:0678aacdd192768b9112272f00332fa7303ef497b058b46a0f4e1cbbdee47350
      lastState:
        terminated:
          containerID: containerd://8df8dc375c28b13b231a2bead71df15e6fa125718454a16ffe458558ec1e44b2
          exitCode: 1
          finishedAt: "2025-03-03T02:55:49Z"
          reason: Error
          startedAt: "2025-03-03T02:55:48Z"
      name: cluster-register
      ready: true
      restartCount: 81
      started: true
      state:
        running:
          startedAt: "2025-03-03T02:56:41Z"
      volumeMounts:
      - mountPath: /cattle-credentials
        name: cattle-credentials
        readOnly: true
        recursiveReadOnly: Disabled
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dc66c
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 172.31.18.33
    hostIPs:
    - ip: 172.31.18.33
    phase: Running
    podIP: 10.42.0.68
    podIPs:
    - ip: 10.42.0.68
    qosClass: BestEffort
    startTime: "2025-02-09T05:56:45Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-02-05T14:24:06Z"
    creationTimestamp: "2025-02-05T14:24:07Z"
    generateName: cattle-cluster-agent-55dd5f54bb-
    labels:
      app: cattle-cluster-agent
      pod-template-hash: 55dd5f54bb
    name: cattle-cluster-agent-55dd5f54bb-wdcx8
    namespace: cattle-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: cattle-cluster-agent-55dd5f54bb
      uid: 2bb122d9-06a2-49f2-96fe-f264fc401428
    resourceVersion: "128349"
    uid: 67158378-2ed6-4ade-8dd8-5e49fe87716b
  spec:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - preference:
            matchExpressions:
            - key: node-role.kubernetes.io/controlplane
              operator: In
              values:
              - "true"
          weight: 100
        - preference:
            matchExpressions:
            - key: node-role.kubernetes.io/control-plane
              operator: In
              values:
              - "true"
          weight: 100
        - preference:
            matchExpressions:
            - key: node-role.kubernetes.io/master
              operator: In
              values:
              - "true"
          weight: 100
        - preference:
            matchExpressions:
            - key: cattle.io/cluster-agent
              operator: In
              values:
              - "true"
          weight: 1
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: beta.kubernetes.io/os
              operator: NotIn
              values:
              - windows
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - cattle-cluster-agent
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - env:
      - name: CATTLE_FEATURES
        value: embedded-cluster-api=false,fleet=false,managed-system-upgrade-controller=true,multi-cluster-management=false,multi-cluster-management-agent=true,provisioningprebootstrap=false,provisioningv2=false,rke2=false,ui-sql-cache=false
      - name: CATTLE_IS_RKE
        value: "false"
      - name: CATTLE_SERVER
        value: https://44.220.0.65.sslip.io
      - name: CATTLE_CA_CHECKSUM
      - name: CATTLE_CLUSTER
        value: "true"
      - name: CATTLE_K8S_MANAGED
        value: "true"
      - name: CATTLE_CLUSTER_REGISTRY
      - name: CATTLE_SERVER_VERSION
        value: v2.10.2
      - name: CATTLE_INSTALL_UUID
        value: dd7c2187-12b9-4774-8ac3-7ac6e676ed0b
      - name: CATTLE_INGRESS_IP_DOMAIN
        value: sslip.io
      - name: STRICT_VERIFY
        value: "false"
      image: rancher/rancher-agent:v2.10.2
      imagePullPolicy: IfNotPresent
      name: cluster-register
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /cattle-credentials
        name: cattle-credentials
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-v222z
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: ip-172-31-18-33
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: cattle
    serviceAccountName: cattle
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/controlplane
      value: "true"
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: cattle-credentials
      secret:
        defaultMode: 320
        secretName: cattle-credentials-8271d07
    - name: kube-api-access-v222z
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:05Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T14:24:07Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:56:35Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:56:35Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T14:24:07Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://940d4c08efeb26891db38a1e28852e94d1c9892e242371e7e77eaf4cf2dab6a4
      image: docker.io/rancher/rancher-agent:v2.10.2
      imageID: docker.io/rancher/rancher-agent@sha256:0678aacdd192768b9112272f00332fa7303ef497b058b46a0f4e1cbbdee47350
      lastState:
        terminated:
          containerID: containerd://44abdef81614c3722b95bca1f0312a395c047307f90c9033cc7a0d402f94df56
          exitCode: 1
          finishedAt: "2025-03-03T02:55:49Z"
          reason: Error
          startedAt: "2025-03-03T02:55:49Z"
      name: cluster-register
      ready: true
      restartCount: 133
      started: true
      state:
        running:
          startedAt: "2025-03-03T02:56:34Z"
      volumeMounts:
      - mountPath: /cattle-credentials
        name: cattle-credentials
        readOnly: true
        recursiveReadOnly: Disabled
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-v222z
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 172.31.18.33
    hostIPs:
    - ip: 172.31.18.33
    phase: Running
    podIP: 10.42.0.75
    podIPs:
    - ip: 10.42.0.75
    qosClass: BestEffort
    startTime: "2025-02-05T14:24:07Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-05T14:26:51Z"
    generateName: rancher-webhook-586f888bb-
    labels:
      app: rancher-webhook
      pod-template-hash: 586f888bb
    name: rancher-webhook-586f888bb-flswq
    namespace: cattle-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: rancher-webhook-586f888bb
      uid: b057887b-5864-4da1-9e46-ab0034267843
    resourceVersion: "128227"
    uid: b50e0e29-4f3f-42be-95dc-91c3072f74e7
  spec:
    containers:
    - env:
      - name: STAMP
      - name: ENABLE_MCM
        value: "false"
      - name: CATTLE_PORT
        value: "9443"
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/rancher-webhook:v0.6.3
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: https
          scheme: HTTPS
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      name: rancher-webhook
      ports:
      - containerPort: 9443
        name: https
        protocol: TCP
      resources: {}
      startupProbe:
        failureThreshold: 60
        httpGet:
          path: /healthz
          port: https
          scheme: HTTPS
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-5gqjg
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: ip-172-31-18-33
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: rancher-webhook
    serviceAccountName: rancher-webhook
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: cattle.io/os
      operator: Equal
      value: linux
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-5gqjg
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:04Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T14:26:51Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:20Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:20Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T14:26:51Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://07e3bd596aba628faa90283e3da024748568efbe0d5f20a6af8e5350b3ba851f
      image: docker.io/rancher/rancher-webhook:v0.6.3
      imageID: docker.io/rancher/rancher-webhook@sha256:79a21351e4536a3e609b41bf8beade3833d100a509a74e868cef4c6a826b50b3
      lastState:
        terminated:
          containerID: containerd://2ad357a2400ae7c38c1b266c4d78c3e528edb7c95a815656dfd3bdd720610400
          exitCode: 255
          finishedAt: "2025-03-03T02:54:52Z"
          reason: Unknown
          startedAt: "2025-03-02T08:06:25Z"
      name: rancher-webhook
      ready: true
      restartCount: 35
      started: true
      state:
        running:
          startedAt: "2025-03-03T02:55:01Z"
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-5gqjg
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 172.31.18.33
    hostIPs:
    - ip: 172.31.18.33
    phase: Running
    podIP: 10.42.0.71
    podIPs:
    - ip: 10.42.0.71
    qosClass: BestEffort
    startTime: "2025-02-05T14:26:51Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-05T14:25:40Z"
    generateName: system-upgrade-controller-5fb67f585d-
    labels:
      pod-template-hash: 5fb67f585d
      upgrade.cattle.io/controller: system-upgrade-controller
    name: system-upgrade-controller-5fb67f585d-z9zzz
    namespace: cattle-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: system-upgrade-controller-5fb67f585d
      uid: df948055-3e53-4ec7-a3cd-baefb413b5c1
    resourceVersion: "128031"
    uid: c07e8a99-f87b-4f21-a8be-b7f55e1dc05f
  spec:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - preference:
            matchExpressions:
            - key: node-role.kubernetes.io/control-plane
              operator: In
              values:
              - "true"
          weight: 100
        - preference:
            matchExpressions:
            - key: node-role.kubernetes.io/master
              operator: In
              values:
              - "true"
          weight: 100
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/os
              operator: NotIn
              values:
              - windows
    containers:
    - env:
      - name: SYSTEM_UPGRADE_CONTROLLER_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.labels['upgrade.cattle.io/controller']
      - name: SYSTEM_UPGRADE_CONTROLLER_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      envFrom:
      - configMapRef:
          name: system-upgrade-controller-config
      image: rancher/system-upgrade-controller:v0.14.2
      imagePullPolicy: IfNotPresent
      name: system-upgrade-controller
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl
        name: etc-ssl
        readOnly: true
      - mountPath: /etc/pki
        name: etc-pki
        readOnly: true
      - mountPath: /etc/ca-certificates
        name: etc-ca-certificates
        readOnly: true
      - mountPath: /tmp
        name: tmp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-twrwl
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: ip-172-31-18-33
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: system-upgrade-controller
    serviceAccountName: system-upgrade-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /etc/ssl
        type: DirectoryOrCreate
      name: etc-ssl
    - hostPath:
        path: /etc/pki
        type: DirectoryOrCreate
      name: etc-pki
    - hostPath:
        path: /etc/ca-certificates
        type: DirectoryOrCreate
      name: etc-ca-certificates
    - emptyDir: {}
      name: tmp
    - name: kube-api-access-twrwl
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:03Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T14:25:40Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:03Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:03Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T14:25:40Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://39ad71a883210b5c2b9752ea98f10541070f7ecff0636803212c35ad49dd9416
      image: docker.io/rancher/system-upgrade-controller:v0.14.2
      imageID: docker.io/rancher/system-upgrade-controller@sha256:3cdbfdd90f814702cefb832fc4bdb09ea93865a4d06c6bafd019d1dc6a9f34c9
      lastState:
        terminated:
          containerID: containerd://d793acb80c92aa50ef9a29b21793124e213ec41d3d7eec55b241e8818cb4e0d3
          exitCode: 255
          finishedAt: "2025-03-03T02:54:52Z"
          reason: Unknown
          startedAt: "2025-03-02T08:06:25Z"
      name: system-upgrade-controller
      ready: true
      restartCount: 35
      started: true
      state:
        running:
          startedAt: "2025-03-03T02:55:02Z"
      volumeMounts:
      - mountPath: /etc/ssl
        name: etc-ssl
        readOnly: true
        recursiveReadOnly: Disabled
      - mountPath: /etc/pki
        name: etc-pki
        readOnly: true
        recursiveReadOnly: Disabled
      - mountPath: /etc/ca-certificates
        name: etc-ca-certificates
        readOnly: true
        recursiveReadOnly: Disabled
      - mountPath: /tmp
        name: tmp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-twrwl
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 172.31.18.33
    hostIPs:
    - ip: 172.31.18.33
    phase: Running
    podIP: 10.42.0.73
    podIPs:
    - ip: 10.42.0.73
    qosClass: BestEffort
    startTime: "2025-02-05T14:25:40Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-02-05T14:24:18Z"
    creationTimestamp: "2025-02-09T05:56:45Z"
    generateName: coredns-8544b8dd7b-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 8544b8dd7b
    name: coredns-8544b8dd7b-6vnhs
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-8544b8dd7b
      uid: 470209f8-cd7f-4c81-83fe-eadad04c1455
    resourceVersion: "128033"
    uid: 0b7257e8-5e1c-4c34-bd23-19b01f369cb7
  spec:
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: rancher/mirrored-coredns-coredns:1.12.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 2
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - all
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /etc/coredns/custom
        name: custom-config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-b8kbk
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: ip-172-31-18-33
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    topologySpreadConstraints:
    - labelSelector:
        matchLabels:
          k8s-app: kube-dns
      maxSkew: 1
      topologyKey: kubernetes.io/hostname
      whenUnsatisfiable: DoNotSchedule
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        - key: NodeHosts
          path: NodeHosts
        name: coredns
      name: config-volume
    - configMap:
        defaultMode: 420
        name: coredns-custom
        optional: true
      name: custom-config-volume
    - name: kube-api-access-b8kbk
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:06Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-09T05:56:45Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:06Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:06Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-09T05:56:45Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://ef2258c2f55ce814b666ba9d911bc3e4e167837e944abb00ddb00d1adfda7af8
      image: docker.io/rancher/mirrored-coredns-coredns:1.12.0
      imageID: docker.io/rancher/mirrored-coredns-coredns@sha256:82979ddf442c593027a57239ad90616deb874e90c365d1a96ad508c2104bdea5
      lastState:
        terminated:
          containerID: containerd://32c07410a56dd1ef00e149a8e3085d224f9751b0ca9845ac029a0b99d811d3df
          exitCode: 255
          finishedAt: "2025-03-03T02:54:52Z"
          reason: Unknown
          startedAt: "2025-03-02T08:06:25Z"
      name: coredns
      ready: true
      restartCount: 26
      started: true
      state:
        running:
          startedAt: "2025-03-03T02:55:04Z"
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
        recursiveReadOnly: Disabled
      - mountPath: /etc/coredns/custom
        name: custom-config-volume
        readOnly: true
        recursiveReadOnly: Disabled
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-b8kbk
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 172.31.18.33
    hostIPs:
    - ip: 172.31.18.33
    phase: Running
    podIP: 10.42.0.76
    podIPs:
    - ip: 10.42.0.76
    qosClass: Burstable
    startTime: "2025-02-09T05:56:45Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      helmcharts.helm.cattle.io/configHash: SHA256=EF658189C81681410C1B7E28CB9F0030170938B99D1CD7EC9E40B82278BB67A8
    creationTimestamp: "2025-02-02T14:26:20Z"
    generateName: helm-install-traefik-
    labels:
      batch.kubernetes.io/controller-uid: 506b1ba9-f9f4-4264-9980-b16dba6e8399
      batch.kubernetes.io/job-name: helm-install-traefik
      controller-uid: 506b1ba9-f9f4-4264-9980-b16dba6e8399
      helmcharts.helm.cattle.io/chart: traefik
      job-name: helm-install-traefik
    name: helm-install-traefik-5nw68
    namespace: kube-system
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: helm-install-traefik
      uid: 506b1ba9-f9f4-4264-9980-b16dba6e8399
    resourceVersion: "753"
    uid: 6bfdc7df-4377-452f-9b9e-5beed1441ab1
  spec:
    containers:
    - args:
      - install
      - --set-string
      - global.systemDefaultRegistry=
      env:
      - name: NAME
        value: traefik
      - name: VERSION
      - name: REPO
      - name: HELM_DRIVER
        value: secret
      - name: CHART_NAMESPACE
        value: kube-system
      - name: CHART
        value: https://%{KUBERNETES_API}%/static/charts/traefik-27.0.201+up27.0.2.tgz
      - name: HELM_VERSION
      - name: TARGET_NAMESPACE
        value: kube-system
      - name: AUTH_PASS_CREDENTIALS
        value: "false"
      - name: INSECURE_SKIP_TLS_VERIFY
        value: "false"
      - name: PLAIN_HTTP
        value: "false"
      - name: NO_PROXY
        value: .svc,.cluster.local,10.42.0.0/16,10.43.0.0/16
      - name: FAILURE_POLICY
        value: reinstall
      image: rancher/klipper-helm:v0.9.3-build20241008
      imagePullPolicy: IfNotPresent
      name: helm
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /home/klipper-helm/.helm
        name: klipper-helm
      - mountPath: /home/klipper-helm/.cache
        name: klipper-cache
      - mountPath: /home/klipper-helm/.config
        name: klipper-config
      - mountPath: /tmp
        name: tmp
      - mountPath: /config
        name: values
      - mountPath: /chart
        name: content
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6thr5
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: ip-172-31-18-33
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: helm-traefik
    serviceAccountName: helm-traefik
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir:
        medium: Memory
      name: klipper-helm
    - emptyDir:
        medium: Memory
      name: klipper-cache
    - emptyDir:
        medium: Memory
      name: klipper-config
    - emptyDir:
        medium: Memory
      name: tmp
    - name: values
      secret:
        defaultMode: 420
        secretName: chart-values-traefik
    - configMap:
        defaultMode: 420
        name: chart-content-traefik
      name: content
    - name: kube-api-access-6thr5
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-02-02T14:26:34Z"
      status: "False"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-02T14:26:20Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-02-02T14:26:32Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-02-02T14:26:32Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-02T14:26:20Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://683365d8e75e9dc565436bfc30963fdbb47c4ae56d59687b960a4c16b5f68c35
      image: docker.io/rancher/klipper-helm:v0.9.3-build20241008
      imageID: docker.io/rancher/klipper-helm@sha256:73ff7ef399717ba8339559054557bd427bdafb47db112165a8c0c358d1ca0283
      lastState: {}
      name: helm
      ready: false
      restartCount: 1
      started: false
      state:
        terminated:
          containerID: containerd://683365d8e75e9dc565436bfc30963fdbb47c4ae56d59687b960a4c16b5f68c35
          exitCode: 0
          finishedAt: "2025-02-02T14:26:32Z"
          message: |
            Installing helm chart
          reason: Completed
          startedAt: "2025-02-02T14:26:29Z"
      volumeMounts:
      - mountPath: /home/klipper-helm/.helm
        name: klipper-helm
      - mountPath: /home/klipper-helm/.cache
        name: klipper-cache
      - mountPath: /home/klipper-helm/.config
        name: klipper-config
      - mountPath: /tmp
        name: tmp
      - mountPath: /config
        name: values
      - mountPath: /chart
        name: content
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6thr5
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 172.31.18.33
    hostIPs:
    - ip: 172.31.18.33
    phase: Succeeded
    qosClass: BestEffort
    startTime: "2025-02-02T14:26:20Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      helmcharts.helm.cattle.io/configHash: SHA256=E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855
    creationTimestamp: "2025-02-02T14:26:20Z"
    generateName: helm-install-traefik-crd-
    labels:
      batch.kubernetes.io/controller-uid: ec5580de-ae16-46db-82e3-d8432011d841
      batch.kubernetes.io/job-name: helm-install-traefik-crd
      controller-uid: ec5580de-ae16-46db-82e3-d8432011d841
      helmcharts.helm.cattle.io/chart: traefik-crd
      job-name: helm-install-traefik-crd
    name: helm-install-traefik-crd-cfrcz
    namespace: kube-system
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: helm-install-traefik-crd
      uid: ec5580de-ae16-46db-82e3-d8432011d841
    resourceVersion: "755"
    uid: 4e43e24e-0e8e-4edd-9a89-210dadbb3a3e
  spec:
    containers:
    - args:
      - install
      env:
      - name: NAME
        value: traefik-crd
      - name: VERSION
      - name: REPO
      - name: HELM_DRIVER
        value: secret
      - name: CHART_NAMESPACE
        value: kube-system
      - name: CHART
        value: https://%{KUBERNETES_API}%/static/charts/traefik-crd-27.0.201+up27.0.2.tgz
      - name: HELM_VERSION
      - name: TARGET_NAMESPACE
        value: kube-system
      - name: AUTH_PASS_CREDENTIALS
        value: "false"
      - name: INSECURE_SKIP_TLS_VERIFY
        value: "false"
      - name: PLAIN_HTTP
        value: "false"
      - name: NO_PROXY
        value: .svc,.cluster.local,10.42.0.0/16,10.43.0.0/16
      - name: FAILURE_POLICY
        value: reinstall
      image: rancher/klipper-helm:v0.9.3-build20241008
      imagePullPolicy: IfNotPresent
      name: helm
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /home/klipper-helm/.helm
        name: klipper-helm
      - mountPath: /home/klipper-helm/.cache
        name: klipper-cache
      - mountPath: /home/klipper-helm/.config
        name: klipper-config
      - mountPath: /tmp
        name: tmp
      - mountPath: /config
        name: values
      - mountPath: /chart
        name: content
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-z96tr
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: ip-172-31-18-33
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: helm-traefik-crd
    serviceAccountName: helm-traefik-crd
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir:
        medium: Memory
      name: klipper-helm
    - emptyDir:
        medium: Memory
      name: klipper-cache
    - emptyDir:
        medium: Memory
      name: klipper-config
    - emptyDir:
        medium: Memory
      name: tmp
    - name: values
      secret:
        defaultMode: 420
        secretName: chart-values-traefik-crd
    - configMap:
        defaultMode: 420
        name: chart-content-traefik-crd
      name: content
    - name: kube-api-access-z96tr
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-02-02T14:26:30Z"
      status: "False"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-02T14:26:20Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-02-02T14:26:29Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-02-02T14:26:29Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-02T14:26:20Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://c1cb68594fdc9fb2c3519109d6f05c77906e9884e5466552a8c17484076df45a
      image: docker.io/rancher/klipper-helm:v0.9.3-build20241008
      imageID: docker.io/rancher/klipper-helm@sha256:73ff7ef399717ba8339559054557bd427bdafb47db112165a8c0c358d1ca0283
      lastState: {}
      name: helm
      ready: false
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://c1cb68594fdc9fb2c3519109d6f05c77906e9884e5466552a8c17484076df45a
          exitCode: 0
          finishedAt: "2025-02-02T14:26:28Z"
          message: |
            Installing helm chart
          reason: Completed
          startedAt: "2025-02-02T14:26:27Z"
      volumeMounts:
      - mountPath: /home/klipper-helm/.helm
        name: klipper-helm
      - mountPath: /home/klipper-helm/.cache
        name: klipper-cache
      - mountPath: /home/klipper-helm/.config
        name: klipper-config
      - mountPath: /tmp
        name: tmp
      - mountPath: /config
        name: values
      - mountPath: /chart
        name: content
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-z96tr
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 172.31.18.33
    hostIPs:
    - ip: 172.31.18.33
    phase: Succeeded
    qosClass: BestEffort
    startTime: "2025-02-02T14:26:20Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-02T14:26:21Z"
    generateName: local-path-provisioner-5cf85fd84d-
    labels:
      app: local-path-provisioner
      pod-template-hash: 5cf85fd84d
    name: local-path-provisioner-5cf85fd84d-5j8ch
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: local-path-provisioner-5cf85fd84d
      uid: 238ad84a-5d83-4480-852b-7877efd458d1
    resourceVersion: "128026"
    uid: 4fda2f1d-348d-4cf6-9a5d-7f7722d6a5b5
  spec:
    containers:
    - command:
      - local-path-provisioner
      - start
      - --config
      - /etc/config/config.json
      env:
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/local-path-provisioner:v0.0.30
      imagePullPolicy: IfNotPresent
      name: local-path-provisioner
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config/
        name: config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-82zbc
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: ip-172-31-18-33
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: local-path-provisioner-service-account
    serviceAccountName: local-path-provisioner-service-account
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: local-path-config
      name: config-volume
    - name: kube-api-access-82zbc
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:05Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-02T14:26:21Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:05Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:05Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-02T14:26:21Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://f9f7ee934139d7a8dad3b406ba1c1d71b3b4cba6c92905d467e485debeb4ce0b
      image: docker.io/rancher/local-path-provisioner:v0.0.30
      imageID: docker.io/rancher/local-path-provisioner@sha256:9b914881170048f80ae9302f36e5b99b4a6b18af73a38adc1c66d12f65d360be
      lastState:
        terminated:
          containerID: containerd://a9fc979ff37568868594db400cd1266c15b9f512cd9504b0ac0b47c951899d0d
          exitCode: 255
          finishedAt: "2025-03-03T02:54:52Z"
          reason: Unknown
          startedAt: "2025-03-02T08:06:25Z"
      name: local-path-provisioner
      ready: true
      restartCount: 46
      started: true
      state:
        running:
          startedAt: "2025-03-03T02:55:01Z"
      volumeMounts:
      - mountPath: /etc/config/
        name: config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-82zbc
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 172.31.18.33
    hostIPs:
    - ip: 172.31.18.33
    phase: Running
    podIP: 10.42.0.72
    podIPs:
    - ip: 10.42.0.72
    qosClass: BestEffort
    startTime: "2025-02-02T14:26:21Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-02T14:26:21Z"
    generateName: metrics-server-5985cbc9d7-
    labels:
      k8s-app: metrics-server
      pod-template-hash: 5985cbc9d7
    name: metrics-server-5985cbc9d7-qps7q
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: metrics-server-5985cbc9d7
      uid: 59c52ce2-85ec-448d-bfb7-b62f2f7fd964
    resourceVersion: "128237"
    uid: fde2f75c-fff1-4245-af9f-3530ecf6235d
  spec:
    containers:
    - args:
      - --cert-dir=/tmp
      - --secure-port=10250
      - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      - --kubelet-use-node-status-port
      - --metric-resolution=15s
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305
      image: rancher/mirrored-metrics-server:v0.7.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /livez
          port: https
          scheme: HTTPS
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: metrics-server
      ports:
      - containerPort: 10250
        name: https
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readyz
          port: https
          scheme: HTTPS
        periodSeconds: 2
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        runAsUser: 1000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: tmp-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-s9kkz
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: ip-172-31-18-33
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: metrics-server
    serviceAccountName: metrics-server
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: tmp-dir
    - name: kube-api-access-s9kkz
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:05Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-02T14:26:21Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:21Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:21Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-02T14:26:21Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://5567a91de741124addb4fdf866d4dfd5d243a09ddb19cf4ed4c283eb0a1b54e2
      image: docker.io/rancher/mirrored-metrics-server:v0.7.2
      imageID: docker.io/rancher/mirrored-metrics-server@sha256:dccf8474fb910fef261d31d9483d7e4c1df7b86cf4d638fb6a7d7c88bd51600a
      lastState:
        terminated:
          containerID: containerd://1078c25ae24c0c947c20e9ccdc1eabdc7594a2a3c242be853e879f7d0338248d
          exitCode: 255
          finishedAt: "2025-03-03T02:54:52Z"
          reason: Unknown
          startedAt: "2025-03-02T08:06:26Z"
      name: metrics-server
      ready: true
      restartCount: 47
      started: true
      state:
        running:
          startedAt: "2025-03-03T02:55:02Z"
      volumeMounts:
      - mountPath: /tmp
        name: tmp-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-s9kkz
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 172.31.18.33
    hostIPs:
    - ip: 172.31.18.33
    phase: Running
    podIP: 10.42.0.74
    podIPs:
    - ip: 10.42.0.74
    qosClass: Burstable
    startTime: "2025-02-02T14:26:21Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-02T14:26:30Z"
    generateName: svclb-traefik-64c0d975-
    labels:
      app: svclb-traefik-64c0d975
      controller-revision-hash: 7785644c65
      pod-template-generation: "1"
      svccontroller.k3s.cattle.io/svcname: traefik
      svccontroller.k3s.cattle.io/svcnamespace: kube-system
    name: svclb-traefik-64c0d975-ccdwh
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: svclb-traefik-64c0d975
      uid: ba9b0b21-d86c-4b37-8137-dd3719a4a20e
    resourceVersion: "128036"
    uid: 9fe6b327-f334-48e4-87bf-d92f15c98578
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-172-31-18-33
    automountServiceAccountToken: false
    containers:
    - env:
      - name: SRC_PORT
        value: "80"
      - name: SRC_RANGES
        value: 0.0.0.0/0
      - name: DEST_PROTO
        value: TCP
      - name: DEST_PORT
        value: "80"
      - name: DEST_IPS
        value: 10.43.42.201
      image: rancher/klipper-lb:v0.4.9
      imagePullPolicy: IfNotPresent
      name: lb-tcp-80
      ports:
      - containerPort: 80
        hostPort: 80
        name: lb-tcp-80
        protocol: TCP
      resources: {}
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
    - env:
      - name: SRC_PORT
        value: "443"
      - name: SRC_RANGES
        value: 0.0.0.0/0
      - name: DEST_PROTO
        value: TCP
      - name: DEST_PORT
        value: "443"
      - name: DEST_IPS
        value: 10.43.42.201
      image: rancher/klipper-lb:v0.4.9
      imagePullPolicy: IfNotPresent
      name: lb-tcp-443
      ports:
      - containerPort: 443
        hostPort: 443
        name: lb-tcp-443
        protocol: TCP
      resources: {}
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: ip-172-31-18-33
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      sysctls:
      - name: net.ipv4.ip_forward
        value: "1"
    serviceAccount: svclb
    serviceAccountName: svclb
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:06Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-02T14:26:30Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:06Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:06Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-02T14:26:30Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://5490ec1cfb8cd00b9236ad4525361e2ea9d3e05905b72a7acb4c0a611293ff7b
      image: docker.io/rancher/klipper-lb:v0.4.9
      imageID: docker.io/rancher/klipper-lb@sha256:dd380f5d89a52f2a07853ff17a6048f805c1f8113b50578f3efc3efb9bcf670a
      lastState:
        terminated:
          containerID: containerd://e7847d0d4236b71a0a6a3e816170cc5bdf095d37aec9bb1090a0524ef26896ed
          exitCode: 255
          finishedAt: "2025-03-03T02:54:52Z"
          reason: Unknown
          startedAt: "2025-03-02T08:06:26Z"
      name: lb-tcp-443
      ready: true
      restartCount: 47
      started: true
      state:
        running:
          startedAt: "2025-03-03T02:55:01Z"
    - containerID: containerd://b6aba15573651447bbc114302d6acffcf2f85dccda59446b90691962dfefaebb
      image: docker.io/rancher/klipper-lb:v0.4.9
      imageID: docker.io/rancher/klipper-lb@sha256:dd380f5d89a52f2a07853ff17a6048f805c1f8113b50578f3efc3efb9bcf670a
      lastState:
        terminated:
          containerID: containerd://60e337d7d5e73de099e1c76766b192dd69b8b4465777cbbe042106faec6e0804
          exitCode: 255
          finishedAt: "2025-03-03T02:54:52Z"
          reason: Unknown
          startedAt: "2025-03-02T08:06:26Z"
      name: lb-tcp-80
      ready: true
      restartCount: 47
      started: true
      state:
        running:
          startedAt: "2025-03-03T02:55:00Z"
    hostIP: 172.31.18.33
    hostIPs:
    - ip: 172.31.18.33
    phase: Running
    podIP: 10.42.0.67
    podIPs:
    - ip: 10.42.0.67
    qosClass: BestEffort
    startTime: "2025-02-02T14:26:30Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-02T14:29:17Z"
    generateName: svclb-traefik-64c0d975-
    labels:
      app: svclb-traefik-64c0d975
      controller-revision-hash: 7785644c65
      pod-template-generation: "1"
      svccontroller.k3s.cattle.io/svcname: traefik
      svccontroller.k3s.cattle.io/svcnamespace: kube-system
    name: svclb-traefik-64c0d975-gjfrw
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: svclb-traefik-64c0d975
      uid: ba9b0b21-d86c-4b37-8137-dd3719a4a20e
    resourceVersion: "128283"
    uid: a5dcebea-4507-4308-a0e4-17fffe6c7c4c
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-172-31-23-7
    automountServiceAccountToken: false
    containers:
    - env:
      - name: SRC_PORT
        value: "80"
      - name: SRC_RANGES
        value: 0.0.0.0/0
      - name: DEST_PROTO
        value: TCP
      - name: DEST_PORT
        value: "80"
      - name: DEST_IPS
        value: 10.43.42.201
      image: rancher/klipper-lb:v0.4.9
      imagePullPolicy: IfNotPresent
      name: lb-tcp-80
      ports:
      - containerPort: 80
        hostPort: 80
        name: lb-tcp-80
        protocol: TCP
      resources: {}
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
    - env:
      - name: SRC_PORT
        value: "443"
      - name: SRC_RANGES
        value: 0.0.0.0/0
      - name: DEST_PROTO
        value: TCP
      - name: DEST_PORT
        value: "443"
      - name: DEST_IPS
        value: 10.43.42.201
      image: rancher/klipper-lb:v0.4.9
      imagePullPolicy: IfNotPresent
      name: lb-tcp-443
      ports:
      - containerPort: 443
        hostPort: 443
        name: lb-tcp-443
        protocol: TCP
      resources: {}
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: ip-172-31-23-7
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      sysctls:
      - name: net.ipv4.ip_forward
        value: "1"
    serviceAccount: svclb
    serviceAccountName: svclb
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:27Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-02T14:29:18Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:27Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:27Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-02T14:29:17Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://9e351f2dd4ff19c31548a148a2121cf2cbd46d9920f6633f664ae186af302b1a
      image: docker.io/rancher/klipper-lb:v0.4.9
      imageID: docker.io/rancher/klipper-lb@sha256:dd380f5d89a52f2a07853ff17a6048f805c1f8113b50578f3efc3efb9bcf670a
      lastState:
        terminated:
          containerID: containerd://07513eaa2f6eca3fcd0713be1494463f4abfcbc6e795fcf23c1cb06f954b5950
          exitCode: 255
          finishedAt: "2025-03-03T02:55:09Z"
          reason: Unknown
          startedAt: "2025-03-02T07:30:55Z"
      name: lb-tcp-443
      ready: true
      restartCount: 39
      started: true
      state:
        running:
          startedAt: "2025-03-03T02:55:27Z"
    - containerID: containerd://ae1e1644f0ea309723c82686dfcd7a8da3ce72c3348ee86cc5b79be1af99f964
      image: docker.io/rancher/klipper-lb:v0.4.9
      imageID: docker.io/rancher/klipper-lb@sha256:dd380f5d89a52f2a07853ff17a6048f805c1f8113b50578f3efc3efb9bcf670a
      lastState:
        terminated:
          containerID: containerd://c4cd717cfb59ea5f98e3fcc818133603d9b78fe5eee2d88448e405948a28a766
          exitCode: 255
          finishedAt: "2025-03-03T02:55:09Z"
          reason: Unknown
          startedAt: "2025-03-02T07:30:55Z"
      name: lb-tcp-80
      ready: true
      restartCount: 39
      started: true
      state:
        running:
          startedAt: "2025-03-03T02:55:27Z"
    hostIP: 172.31.23.7
    hostIPs:
    - ip: 172.31.23.7
    phase: Running
    podIP: 10.42.1.136
    podIPs:
    - ip: 10.42.1.136
    qosClass: BestEffort
    startTime: "2025-02-02T14:29:18Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      prometheus.io/path: /metrics
      prometheus.io/port: "9100"
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-02-05T05:56:09Z"
    generateName: traefik-5d45fc8cc9-
    labels:
      app.kubernetes.io/instance: traefik-kube-system
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: traefik
      helm.sh/chart: traefik-27.0.201_up27.0.2
      pod-template-hash: 5d45fc8cc9
    name: traefik-5d45fc8cc9-mmh4t
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: traefik-5d45fc8cc9
      uid: 5eb73b9d-7a72-4616-b644-44664ab1c5c7
    resourceVersion: "128016"
    uid: 11e13bb6-3d46-41ce-af53-9072a4b69e07
  spec:
    containers:
    - args:
      - --global.checknewversion
      - --global.sendanonymoususage
      - --entrypoints.metrics.address=:9100/tcp
      - --entrypoints.traefik.address=:9000/tcp
      - --entrypoints.web.address=:8000/tcp
      - --entrypoints.websecure.address=:8443/tcp
      - --api.dashboard=true
      - --ping=true
      - --metrics.prometheus=true
      - --metrics.prometheus.entrypoint=metrics
      - --providers.kubernetescrd
      - --providers.kubernetesingress
      - --providers.kubernetesingress.ingressendpoint.publishedservice=kube-system/traefik
      - --entrypoints.websecure.http.tls=true
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/mirrored-library-traefik:2.11.18
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /ping
          port: 9000
          scheme: HTTP
        initialDelaySeconds: 2
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 2
      name: traefik
      ports:
      - containerPort: 9100
        name: metrics
        protocol: TCP
      - containerPort: 9000
        name: traefik
        protocol: TCP
      - containerPort: 8000
        name: web
        protocol: TCP
      - containerPort: 8443
        name: websecure
        protocol: TCP
      readinessProbe:
        failureThreshold: 1
        httpGet:
          path: /ping
          port: 9000
          scheme: HTTP
        initialDelaySeconds: 2
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 2
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /data
        name: data
      - mountPath: /tmp
        name: tmp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-jvqnx
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: ip-172-31-18-33
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroupChangePolicy: OnRootMismatch
      runAsGroup: 65532
      runAsNonRoot: true
      runAsUser: 65532
    serviceAccount: traefik
    serviceAccountName: traefik
    terminationGracePeriodSeconds: 60
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: data
    - emptyDir: {}
      name: tmp
    - name: kube-api-access-jvqnx
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:04Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T05:56:09Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:05Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:05Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T05:56:09Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://dd6e20f7aaf2cdf71eb5d2ea6e5bed9ba60b4580b4771cdbac170c5fc95368bf
      image: docker.io/rancher/mirrored-library-traefik:2.11.18
      imageID: docker.io/rancher/mirrored-library-traefik@sha256:25df7bff0b414867f16a74c571c0dc84920404e45cc7780976cec77809230e09
      lastState:
        terminated:
          containerID: containerd://cb289606946852d44212ae50e240694f8d16f6b1c8c1a7c25c13a55812ce46f5
          exitCode: 255
          finishedAt: "2025-03-03T02:54:52Z"
          reason: Unknown
          startedAt: "2025-03-02T08:06:25Z"
      name: traefik
      ready: true
      restartCount: 37
      started: true
      state:
        running:
          startedAt: "2025-03-03T02:55:01Z"
      volumeMounts:
      - mountPath: /data
        name: data
      - mountPath: /tmp
        name: tmp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-jvqnx
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 172.31.18.33
    hostIPs:
    - ip: 172.31.18.33
    phase: Running
    podIP: 10.42.0.70
    podIPs:
    - ip: 10.42.0.70
    qosClass: BestEffort
    startTime: "2025-02-05T05:56:09Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
    creationTimestamp: "2025-02-09T06:54:33Z"
    generateName: node-exporter-prometheus-node-exporter-
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: node-exporter
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-node-exporter
      app.kubernetes.io/part-of: prometheus-node-exporter
      app.kubernetes.io/version: 1.8.2
      controller-revision-hash: 7c7f549946
      helm.sh/chart: prometheus-node-exporter-4.43.1
      pod-template-generation: "1"
    name: node-exporter-prometheus-node-exporter-79pzh
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter-prometheus-node-exporter
      uid: 3f32c744-b158-428b-819d-32135e07c334
    resourceVersion: "128232"
    uid: 604fc7c3-5058-4e82-8798-9f46449f22ed
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-172-31-23-7
    automountServiceAccountToken: false
    containers:
    - args:
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --path.udev.data=/host/root/run/udev/data
      - --web.listen-address=[$(HOST_IP)]:9100
      env:
      - name: HOST_IP
        value: 0.0.0.0
      image: quay.io/prometheus/node-exporter:v1.8.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 9100
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: node-exporter
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 9100
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
        readOnly: true
      - mountPath: /host/sys
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    nodeName: ip-172-31-23-7
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: node-exporter-prometheus-node-exporter
    serviceAccountName: node-exporter-prometheus-node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:12Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-09T10:15:09Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:20Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:20Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-09T06:54:33Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://205686bb97b6e639a678fdc23f38820809360a32718c0155e3a4066b37b6fd9d
      image: quay.io/prometheus/node-exporter:v1.8.2
      imageID: quay.io/prometheus/node-exporter@sha256:4032c6d5bfd752342c3e631c2f1de93ba6b86c41db6b167b9a35372c139e7706
      lastState:
        terminated:
          containerID: containerd://9217fb3dcd9d8f48cf0fb5dbc3ce321eb63c1fedebaf22005083650dc051b156
          exitCode: 255
          finishedAt: "2025-03-03T02:55:09Z"
          reason: Unknown
          startedAt: "2025-03-02T07:30:44Z"
      name: node-exporter
      ready: true
      restartCount: 19
      started: true
      state:
        running:
          startedAt: "2025-03-03T02:55:12Z"
      volumeMounts:
      - mountPath: /host/proc
        name: proc
        readOnly: true
        recursiveReadOnly: Disabled
      - mountPath: /host/sys
        name: sys
        readOnly: true
        recursiveReadOnly: Disabled
      - mountPath: /host/root
        name: root
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 172.31.23.7
    hostIPs:
    - ip: 172.31.23.7
    phase: Running
    podIP: 172.31.23.7
    podIPs:
    - ip: 172.31.23.7
    qosClass: BestEffort
    startTime: "2025-02-09T10:15:09Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
    creationTimestamp: "2025-02-09T06:54:33Z"
    generateName: node-exporter-prometheus-node-exporter-
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: node-exporter
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-node-exporter
      app.kubernetes.io/part-of: prometheus-node-exporter
      app.kubernetes.io/version: 1.8.2
      controller-revision-hash: 7c7f549946
      helm.sh/chart: prometheus-node-exporter-4.43.1
      pod-template-generation: "1"
    name: node-exporter-prometheus-node-exporter-wg5k2
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter-prometheus-node-exporter
      uid: 3f32c744-b158-428b-819d-32135e07c334
    resourceVersion: "128085"
    uid: bf8461c2-8508-4c65-88fe-2a8354e0132c
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-172-31-18-33
    automountServiceAccountToken: false
    containers:
    - args:
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --path.udev.data=/host/root/run/udev/data
      - --web.listen-address=[$(HOST_IP)]:9100
      env:
      - name: HOST_IP
        value: 0.0.0.0
      image: quay.io/prometheus/node-exporter:v1.8.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 9100
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: node-exporter
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 9100
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
        readOnly: true
      - mountPath: /host/sys
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    nodeName: ip-172-31-18-33
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: node-exporter-prometheus-node-exporter
    serviceAccountName: node-exporter-prometheus-node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:04Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-09T06:54:33Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:07Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:07Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-09T06:54:33Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://ee34df83132c1af337c68ef3d6d341dc36cf74b4a84d979997d2465148a2b2b9
      image: quay.io/prometheus/node-exporter:v1.8.2
      imageID: quay.io/prometheus/node-exporter@sha256:4032c6d5bfd752342c3e631c2f1de93ba6b86c41db6b167b9a35372c139e7706
      lastState:
        terminated:
          containerID: containerd://a537996cb20e637d195da8c5b8f5f9a841a66363fb4a18246f11892b6dea6e63
          exitCode: 255
          finishedAt: "2025-03-03T02:54:52Z"
          reason: Unknown
          startedAt: "2025-03-02T08:06:25Z"
      name: node-exporter
      ready: true
      restartCount: 26
      started: true
      state:
        running:
          startedAt: "2025-03-03T02:55:00Z"
      volumeMounts:
      - mountPath: /host/proc
        name: proc
        readOnly: true
        recursiveReadOnly: Disabled
      - mountPath: /host/sys
        name: sys
        readOnly: true
        recursiveReadOnly: Disabled
      - mountPath: /host/root
        name: root
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 172.31.18.33
    hostIPs:
    - ip: 172.31.18.33
    phase: Running
    podIP: 172.31.18.33
    podIPs:
    - ip: 172.31.18.33
    qosClass: BestEffort
    startTime: "2025-02-09T06:54:33Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-11T12:50:13Z"
    generateName: nginx-deployment-54b9c68f67-
    labels:
      app: nginx
      pod-template-hash: 54b9c68f67
    name: nginx-deployment-54b9c68f67-2p8hx
    namespace: nginx
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: nginx-deployment-54b9c68f67
      uid: e6aa2e43-8555-479e-900f-6779d29973fc
    resourceVersion: "128056"
    uid: f6f01a7f-fd9d-42e5-8700-3a8e66f7ab26
  spec:
    containers:
    - image: nginx:latest
      imagePullPolicy: Always
      name: nginx
      ports:
      - containerPort: 80
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tj7d4
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: ip-172-31-18-33
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-tj7d4
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:06Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-11T12:50:13Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:06Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:06Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-11T12:50:13Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://53ab8df31f678987371c02877705861e2fd7e8ef783c7557d7fd092ea348f467
      image: docker.io/library/nginx:latest
      imageID: docker.io/library/nginx@sha256:9d6b58feebd2dbd3c56ab5853333d627cc6e281011cfd6050fa4bcf2072c9496
      lastState:
        terminated:
          containerID: containerd://18cfecfff79a6ac110d97bdb99ccda33b68b2d31ecd0f14e256db78e3da2834f
          exitCode: 255
          finishedAt: "2025-03-03T02:54:52Z"
          reason: Unknown
          startedAt: "2025-03-02T08:06:25Z"
      name: nginx
      ready: true
      restartCount: 19
      started: true
      state:
        running:
          startedAt: "2025-03-03T02:55:01Z"
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tj7d4
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 172.31.18.33
    hostIPs:
    - ip: 172.31.18.33
    phase: Running
    podIP: 10.42.0.66
    podIPs:
    - ip: 10.42.0.66
    qosClass: BestEffort
    startTime: "2025-02-11T12:50:13Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-11T12:50:13Z"
    generateName: nginx-deployment-54b9c68f67-
    labels:
      app: nginx
      pod-template-hash: 54b9c68f67
    name: nginx-deployment-54b9c68f67-wfv22
    namespace: nginx
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: nginx-deployment-54b9c68f67
      uid: e6aa2e43-8555-479e-900f-6779d29973fc
    resourceVersion: "128060"
    uid: d1423aec-934e-4438-a5c6-056800a0fd74
  spec:
    containers:
    - image: nginx:latest
      imagePullPolicy: Always
      name: nginx
      ports:
      - containerPort: 80
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-h8tlt
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: ip-172-31-18-33
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-h8tlt
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:06Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-11T12:50:13Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:06Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:06Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-11T12:50:13Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://d264119a50acd1cd07cfdea98e43af72c5a10b2c86f0faf42225e423cc6f2210
      image: docker.io/library/nginx:latest
      imageID: docker.io/library/nginx@sha256:9d6b58feebd2dbd3c56ab5853333d627cc6e281011cfd6050fa4bcf2072c9496
      lastState:
        terminated:
          containerID: containerd://5c5ca5631d49da5b71566b7b1c3dd20326838f33256bc5a2bbd40b9bc5f98d38
          exitCode: 255
          finishedAt: "2025-03-03T02:54:52Z"
          reason: Unknown
          startedAt: "2025-03-02T08:06:25Z"
      name: nginx
      ready: true
      restartCount: 19
      started: true
      state:
        running:
          startedAt: "2025-03-03T02:55:01Z"
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-h8tlt
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 172.31.18.33
    hostIPs:
    - ip: 172.31.18.33
    phase: Running
    podIP: 10.42.0.69
    podIPs:
    - ip: 10.42.0.69
    qosClass: BestEffort
    startTime: "2025-02-11T12:50:13Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-06T15:27:39Z"
    generateName: node-agent-
    labels:
      component: velero
      controller-revision-hash: 9dcbb9b8d
      name: node-agent
      pod-template-generation: "1"
    name: node-agent-fs8w9
    namespace: velero
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-agent
      uid: 13178b61-4c3a-4cec-af1c-f3e6c679e0c2
    resourceVersion: "128049"
    uid: 54c34416-f30e-4003-93b8-febd2c7723ba
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-172-31-18-33
    containers:
    - args:
      - node-agent
      - server
      - --features=
      command:
      - /velero
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: VELERO_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: VELERO_SCRATCH_DIR
        value: /scratch
      image: velero/velero:v1.15.2
      imagePullPolicy: IfNotPresent
      name: node-agent
      ports:
      - containerPort: 8085
        name: metrics
        protocol: TCP
      resources: {}
      securityContext:
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host_pods
        mountPropagation: HostToContainer
        name: host-pods
      - mountPath: /var/lib/kubelet/plugins
        mountPropagation: HostToContainer
        name: host-plugins
      - mountPath: /scratch
        name: scratch
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-ldcmt
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: ip-172-31-18-33
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsUser: 0
    serviceAccount: velero
    serviceAccountName: velero
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/lib/kubelet/pods
        type: ""
      name: host-pods
    - hostPath:
        path: /var/lib/kubelet/plugins
        type: ""
      name: host-plugins
    - emptyDir: {}
      name: scratch
    - name: kube-api-access-ldcmt
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:06Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-06T15:27:40Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:06Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:06Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-06T15:27:40Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://01c0e50335b2d9e8f859ac7c5ce98b647531141432ea58cc1d1dc11c7133b284
      image: docker.io/velero/velero:v1.15.2
      imageID: docker.io/velero/velero@sha256:668467fdf39f3a610ed6f27431f38a6fbb6143a2ab302ad3e839b0074aaeba39
      lastState:
        terminated:
          containerID: containerd://5497882f50d7fe8b472a74f285a21ad8ad31abad3e5c95e7dff43daac00fa4bc
          exitCode: 255
          finishedAt: "2025-03-03T02:54:52Z"
          reason: Unknown
          startedAt: "2025-03-02T08:06:25Z"
      name: node-agent
      ready: true
      restartCount: 30
      started: true
      state:
        running:
          startedAt: "2025-03-03T02:55:04Z"
      volumeMounts:
      - mountPath: /host_pods
        name: host-pods
      - mountPath: /var/lib/kubelet/plugins
        name: host-plugins
      - mountPath: /scratch
        name: scratch
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-ldcmt
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 172.31.18.33
    hostIPs:
    - ip: 172.31.18.33
    phase: Running
    podIP: 10.42.0.77
    podIPs:
    - ip: 10.42.0.77
    qosClass: BestEffort
    startTime: "2025-02-06T15:27:40Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-06T15:27:40Z"
    generateName: node-agent-
    labels:
      component: velero
      controller-revision-hash: 9dcbb9b8d
      name: node-agent
      pod-template-generation: "1"
    name: node-agent-zx7zg
    namespace: velero
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-agent
      uid: 13178b61-4c3a-4cec-af1c-f3e6c679e0c2
    resourceVersion: "128217"
    uid: cac1b203-7b68-4e71-bf59-e1d907af2293
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-172-31-23-7
    containers:
    - args:
      - node-agent
      - server
      - --features=
      command:
      - /velero
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: VELERO_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: VELERO_SCRATCH_DIR
        value: /scratch
      image: velero/velero:v1.15.2
      imagePullPolicy: IfNotPresent
      name: node-agent
      ports:
      - containerPort: 8085
        name: metrics
        protocol: TCP
      resources: {}
      securityContext:
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host_pods
        mountPropagation: HostToContainer
        name: host-pods
      - mountPath: /var/lib/kubelet/plugins
        mountPropagation: HostToContainer
        name: host-plugins
      - mountPath: /scratch
        name: scratch
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-q8zcx
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: ip-172-31-23-7
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsUser: 0
    serviceAccount: velero
    serviceAccountName: velero
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/lib/kubelet/pods
        type: ""
      name: host-pods
    - hostPath:
        path: /var/lib/kubelet/plugins
        type: ""
      name: host-plugins
    - emptyDir: {}
      name: scratch
    - name: kube-api-access-q8zcx
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:12Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-06T15:27:40Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:12Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:12Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-06T15:27:40Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://67521327422bf2e1517778093c63beb471eaca12d610123951ca2e6b28991b04
      image: docker.io/velero/velero:v1.15.2
      imageID: docker.io/velero/velero@sha256:668467fdf39f3a610ed6f27431f38a6fbb6143a2ab302ad3e839b0074aaeba39
      lastState:
        terminated:
          containerID: containerd://5a2fb4fdf14016c69ec0930ec627acf7ea58ba061d2974278bc6c4ca72196419
          exitCode: 255
          finishedAt: "2025-03-03T02:55:09Z"
          reason: Unknown
          startedAt: "2025-03-02T07:30:44Z"
      name: node-agent
      ready: true
      restartCount: 22
      started: true
      state:
        running:
          startedAt: "2025-03-03T02:55:12Z"
      volumeMounts:
      - mountPath: /host_pods
        name: host-pods
      - mountPath: /var/lib/kubelet/plugins
        name: host-plugins
      - mountPath: /scratch
        name: scratch
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-q8zcx
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 172.31.23.7
    hostIPs:
    - ip: 172.31.23.7
    phase: Running
    podIP: 10.42.1.135
    podIPs:
    - ip: 10.42.1.135
    qosClass: BestEffort
    startTime: "2025-02-06T15:27:40Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-02-09T06:08:17Z"
      prometheus.io/path: /metrics
      prometheus.io/port: "8085"
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-02-09T06:08:17Z"
    generateName: velero-5844478ff5-
    labels:
      component: velero
      deploy: velero
      pod-template-hash: 5844478ff5
    name: velero-5844478ff5-pczwb
    namespace: velero
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: velero-5844478ff5
      uid: aa4b2103-7f20-4a67-bb5e-34e9d6f9768d
    resourceVersion: "128169"
    uid: b31ae451-15fe-4016-92ae-568d268e6493
  spec:
    containers:
    - args:
      - server
      - --features=
      - --uploader-type=kopia
      command:
      - /velero
      env:
      - name: VELERO_SCRATCH_DIR
        value: /scratch
      - name: VELERO_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: LD_LIBRARY_PATH
        value: /plugins
      image: velero/velero:v1.15.2
      imagePullPolicy: IfNotPresent
      name: velero
      ports:
      - containerPort: 8085
        name: metrics
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 512Mi
        requests:
          cpu: 500m
          memory: 128Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /plugins
        name: plugins
      - mountPath: /scratch
        name: scratch
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-c5768
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    initContainers:
    - image: velero/velero-plugin-for-aws:v1.10.0
      imagePullPolicy: IfNotPresent
      name: velero-velero-plugin-for-aws
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /target
        name: plugins
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-c5768
        readOnly: true
    nodeName: ip-172-31-18-33
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: velero
    serviceAccountName: velero
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: plugins
    - emptyDir: {}
      name: scratch
    - name: kube-api-access-c5768
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:05Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-09T06:08:19Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:09Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-03-03T02:55:09Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-09T06:08:17Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://89773ba95171f3b0d0db6d742ba594a57bd9bf990af8ce571b9869005044874d
      image: docker.io/velero/velero:v1.15.2
      imageID: docker.io/velero/velero@sha256:668467fdf39f3a610ed6f27431f38a6fbb6143a2ab302ad3e839b0074aaeba39
      lastState:
        terminated:
          containerID: containerd://4fb4aaa71f1655f6ad50d5e8d9589847cd93cb9e6f5bea04845f19b35cb55040
          exitCode: 255
          finishedAt: "2025-03-03T02:54:52Z"
          reason: Unknown
          startedAt: "2025-03-02T08:06:30Z"
      name: velero
      ready: true
      restartCount: 25
      started: true
      state:
        running:
          startedAt: "2025-03-03T02:55:09Z"
      volumeMounts:
      - mountPath: /plugins
        name: plugins
      - mountPath: /scratch
        name: scratch
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-c5768
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 172.31.18.33
    hostIPs:
    - ip: 172.31.18.33
    initContainerStatuses:
    - containerID: containerd://3663bcf827750e570b748edc94f7e25e24a7cb1ab42cdfc56b2017c2f0242204
      image: docker.io/velero/velero-plugin-for-aws:v1.10.0
      imageID: docker.io/velero/velero-plugin-for-aws@sha256:80f84902d9f644aecce043908867a6629cc89b7ddb8c6633ad0e8bbe2c364e7e
      lastState: {}
      name: velero-velero-plugin-for-aws
      ready: true
      restartCount: 26
      started: false
      state:
        terminated:
          containerID: containerd://3663bcf827750e570b748edc94f7e25e24a7cb1ab42cdfc56b2017c2f0242204
          exitCode: 0
          finishedAt: "2025-03-03T02:55:05Z"
          reason: Completed
          startedAt: "2025-03-03T02:55:04Z"
      volumeMounts:
      - mountPath: /target
        name: plugins
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-c5768
        readOnly: true
        recursiveReadOnly: Disabled
    phase: Running
    podIP: 10.42.0.79
    podIPs:
    - ip: 10.42.0.79
    qosClass: Burstable
    startTime: "2025-02-09T06:08:17Z"
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/3zQz06EMBAG8HeZM4u7oLvAUU9ejAdfYFo+XEzpNMxw2Gx4d1NITPTgsX++X7/OnSYY92xM3Z04RjG2UaLmpbgveFNYOY9SejYLKEd5GHvqaAiAHfgT0Q5OxNRmTrQW5GdsxMc4QY2nRF1cQigosEP4F76yXjNdt21/dPXpOLjBVQ3a8/lSn6qh9xeu6/bpEZVrfJNfizzhdxvaNzWxzye7ftgv6E0NU85pgs9VfFjUML++U0dvEkEFKQK8ybxNJKU/+lqQ3VKWX36i2TO2ZftcEO6fOXD0yMS6rt8BAAD//1IdqY9lAQAA
      objectset.rio.cattle.io/id: fleet-agent-bootstrap
    creationTimestamp: "2025-02-05T14:24:39Z"
    labels:
      objectset.rio.cattle.io/hash: f399d0b310fbfb28e9667312fdc7a33954e2b8c8
    name: fleet-agent
    namespace: cattle-fleet-system
    resourceVersion: "56322"
    uid: c8f496f2-cf0f-41cf-bb41-8772af4b7e85
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    selector:
      app: fleet-agent
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"cattle-cluster-agent","namespace":"cattle-system"},"spec":{"ports":[{"name":"http","port":80,"protocol":"TCP","targetPort":80},{"name":"https-internal","port":443,"protocol":"TCP","targetPort":444}],"selector":{"app":"cattle-cluster-agent"}}}
    creationTimestamp: "2025-02-05T01:41:14Z"
    name: cattle-cluster-agent
    namespace: cattle-system
    resourceVersion: "42160"
    uid: d1dc4862-4221-4d38-a982-34aeb0cc6b45
  spec:
    clusterIP: 10.43.15.147
    clusterIPs:
    - 10.43.15.147
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: 80
    - name: https-internal
      port: 443
      protocol: TCP
      targetPort: 444
    selector:
      app: cattle-cluster-agent
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: rancher-webhook
      meta.helm.sh/release-namespace: cattle-system
    creationTimestamp: "2025-02-05T14:26:51Z"
    labels:
      app.kubernetes.io/managed-by: Helm
    name: rancher-webhook
    namespace: cattle-system
    resourceVersion: "56638"
    uid: 1ece41b5-b984-4b8b-bd1c-340cadaf44e5
  spec:
    clusterIP: 10.43.56.123
    clusterIPs:
    - 10.43.56.123
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: 9443
    selector:
      app: rancher-webhook
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2025-02-02T14:26:14Z"
    labels:
      component: apiserver
      provider: kubernetes
    name: kubernetes
    namespace: default
    resourceVersion: "201"
    uid: 5afa5eef-afaf-4c2e-8afc-483e0018e8e4
  spec:
    clusterIP: 10.43.0.1
    clusterIPs:
    - 10.43.0.1
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: 6443
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/4ySQYvbMBCF/0p5Z9m142TjFfRQdimUQgmk7aXsQZYnG9W2JKRJSgj+70WJl00b0vZm8958vHmjI5Q33yhE4ywk9iUEOmNbSKwp7I0mCAzEqlWsII9Q1jpWbJyN6dc1P0hzJM6DcblWzD3lxr01iQBxU3c/LYXsed9BoqvihbIvxZtPxrbv3rets/9EWDUQJLQL1Nr4X/bolU4z3a6hLB4i0wABH9xAvKVdTG7vAkPivlxUV1rUQfkE4LAjjAK9aqg/1dHVMVPev8DPidJnsMR0mtb9LjKFLE71Tpg/bdNeDy7Q4+f1X/baqriFRKNpVlez+7ouy+W8UkVV36lmURab2eZuSZvlfDYv9GKZ8k7si4i3ahkFoiedVptyf1xBoizyeZUXeVlAvAoR8vul9CRg/Ac1mP6wcr3Rh/SojH3uac1Kd6lXFzhNHV8indOcy19Up+LZaddD4uvjCqO4dGas/S33l4ff3ANxMPqVne567X8SiNSTZhduHHMcx18BAAD//5X9LCMyAwAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: k3s.cattle.io/v1, Kind=Addon
      objectset.rio.cattle.io/owner-name: coredns
      objectset.rio.cattle.io/owner-namespace: kube-system
      prometheus.io/port: "9153"
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-02-02T14:26:17Z"
    labels:
      k8s-app: kube-dns
      kubernetes.io/cluster-service: "true"
      kubernetes.io/name: CoreDNS
      objectset.rio.cattle.io/hash: bce283298811743a0386ab510f2f67ef74240c57
    name: kube-dns
    namespace: kube-system
    resourceVersion: "268"
    uid: 2554b2e8-2592-4950-8576-b7de2c16a1b6
  spec:
    clusterIP: 10.43.0.10
    clusterIPs:
    - 10.43.0.10
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: dns
      port: 53
      protocol: UDP
      targetPort: 53
    - name: dns-tcp
      port: 53
      protocol: TCP
      targetPort: 53
    - name: metrics
      port: 9153
      protocol: TCP
      targetPort: 9153
    selector:
      k8s-app: kube-dns
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/4SQQWsbMRCF/0p5Z9nNep04FfRQWnopBUNKL6WHWe04VleWhGa8xZj970UbFxLaJCchvZn3vqczKPvvXMSnCIuxgcHgYw+LOy6jdwyDAyv1pAR7BsWYlNSnKPWaul/sVFiXxaelI9XAS5/e+uoA86yefkcui/txgMXQyiNlbMybLz727z/0fYqvWkQ6MGxFLN7JQriMXObjgf31bcnkqsVw7HghJ1E+YDII1HGYO1ahRFaWuujCUfRRhIWWY016Onbh+vqE6wWePckeFnTdt527uWrc7abhZtXuqF11q83uev2uu2HabK46t1tTJfxvdTy8P1NKMrtayefPdPDhtE3BuxMstoV3XD4dKdwpuQEGORUV2B/nvzl71SwXAXa9bg1ySZpcCrD49nELA6Vyz7qdJy4L008D4cBOU5l/81YWlPO/4NM0/QkAAP//sKxN444CAAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: k3s.cattle.io/v1, Kind=Addon
      objectset.rio.cattle.io/owner-name: metrics-server-service
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2025-02-02T14:26:18Z"
    labels:
      kubernetes.io/cluster-service: "true"
      kubernetes.io/name: Metrics-server
      objectset.rio.cattle.io/hash: a5d3bc601c871e123fa32b27f549b6ea770bcf4a
    name: metrics-server
    namespace: kube-system
    resourceVersion: "313"
    uid: 69e67d09-484a-410b-93d0-719708a3edf1
  spec:
    clusterIP: 10.43.101.62
    clusterIPs:
    - 10.43.101.62
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: PreferDualStack
    ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: https
    selector:
      k8s-app: metrics-server
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      field.cattle.io/publicEndpoints: '[{"addresses":["172.31.18.33","172.31.23.7"],"port":80,"protocol":"TCP","serviceName":"kube-system:traefik","allNodes":false},{"addresses":["172.31.18.33","172.31.23.7"],"port":443,"protocol":"TCP","serviceName":"kube-system:traefik","allNodes":false}]'
      meta.helm.sh/release-name: traefik
      meta.helm.sh/release-namespace: kube-system
    creationTimestamp: "2025-02-02T14:26:30Z"
    finalizers:
    - service.kubernetes.io/load-balancer-cleanup
    labels:
      app.kubernetes.io/instance: traefik-kube-system
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: traefik
      helm.sh/chart: traefik-27.0.201_up27.0.2
    name: traefik
    namespace: kube-system
    resourceVersion: "128039"
    uid: 64c0d975-8bf4-497b-a219-495a8f2f90b7
  spec:
    allocateLoadBalancerNodePorts: true
    clusterIP: 10.43.42.201
    clusterIPs:
    - 10.43.42.201
    externalTrafficPolicy: Cluster
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: PreferDualStack
    ports:
    - name: web
      nodePort: 30922
      port: 80
      protocol: TCP
      targetPort: web
    - name: websecure
      nodePort: 32442
      port: 443
      protocol: TCP
      targetPort: websecure
    selector:
      app.kubernetes.io/instance: traefik-kube-system
      app.kubernetes.io/name: traefik
    sessionAffinity: None
    type: LoadBalancer
  status:
    loadBalancer:
      ingress:
      - ip: 172.31.18.33
        ipMode: VIP
      - ip: 172.31.23.7
        ipMode: VIP
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: node-exporter
      meta.helm.sh/release-namespace: monitoring
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-02-09T06:54:33Z"
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: node-exporter
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-node-exporter
      app.kubernetes.io/part-of: prometheus-node-exporter
      app.kubernetes.io/version: 1.8.2
      helm.sh/chart: prometheus-node-exporter-4.43.1
    name: node-exporter-prometheus-node-exporter
    namespace: monitoring
    resourceVersion: "69975"
    uid: e0c9eefd-3801-483f-8803-af737f24f28f
  spec:
    clusterIP: 10.43.187.156
    clusterIPs:
    - 10.43.187.156
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: metrics
      port: 9100
      protocol: TCP
      targetPort: 9100
    selector:
      app.kubernetes.io/instance: node-exporter
      app.kubernetes.io/name: prometheus-node-exporter
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      field.cattle.io/publicEndpoints: '[{"port":30088,"protocol":"TCP","serviceName":"nginx:nginx-service","allNodes":true}]'
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"nginx-service","namespace":"nginx"},"spec":{"ports":[{"nodePort":30088,"port":80,"protocol":"TCP","targetPort":80}],"selector":{"app":"nginx"},"type":"NodePort"}}
    creationTimestamp: "2025-02-11T12:50:59Z"
    name: nginx-service
    namespace: nginx
    resourceVersion: "89526"
    uid: 925ad5c2-6658-498e-8cc2-9e66724056de
  spec:
    clusterIP: 10.43.36.193
    clusterIPs:
    - 10.43.36.193
    externalTrafficPolicy: Cluster
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - nodePort: 30088
      port: 80
      protocol: TCP
      targetPort: 80
    selector:
      app: nginx
    sessionAffinity: None
    type: NodePort
  status:
    loadBalancer: {}
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
      field.cattle.io/publicEndpoints: '[{"nodeName":":ip-172-31-18-33","addresses":["172.31.18.33"],"port":80,"protocol":"TCP","podName":"kube-system:svclb-traefik-64c0d975-ccdwh","allNodes":false},{"nodeName":":ip-172-31-18-33","addresses":["172.31.18.33"],"port":443,"protocol":"TCP","podName":"kube-system:svclb-traefik-64c0d975-ccdwh","allNodes":false},{"nodeName":":ip-172-31-23-7","addresses":["172.31.23.7"],"port":80,"protocol":"TCP","podName":"kube-system:svclb-traefik-64c0d975-gjfrw","allNodes":false},{"nodeName":":ip-172-31-23-7","addresses":["172.31.23.7"],"port":443,"protocol":"TCP","podName":"kube-system:svclb-traefik-64c0d975-gjfrw","allNodes":false}]'
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/8RVwW7jNhD9lWLOsizHStYW0EOQBEXQrmPY3l4WRjCiRjFriiTIkTZGoH8vKDtZpWsnQYFu4YNBcuZx+N7ozROglX+S89JoyACt9cNmBBFspS4gg2ukyuglMURQEWOBjJA9AWptGFka7cPS5H+RYE8cO2ligcyKYmmGMmBAdPLcfNPkBg/NFjIYNqPol9+lLn5dkmukoHfzNFYEGbBDKuX2Q+Heogg52zqngd95pgraCISj7jErWZFnrCxkulYqAoU5qTefuEG/gQwm44tS5IKSs7PivEA6z8cXF9O0pBFhOZ5MxXSM5adCQAS+EcJodkYpcvF27Hto2hTkSZFg4yCDEpWnd1J8I34g4gPxJ5g4QPlGqHxwABxcpCIppp/OYX9+ItVbEoGp7/U/QYUsNn+8kIjWngZv2wiYKquQqcvt9dsHBHoT++dR2CMCazaVqTUfGvpSiLBamS1pyDptIwiXoNTkPGRfn4B00/0f6lkuru7nd4sVRNCgqsPWJIE2ehWwuJz9drPshSRx9xu+iry+Wa7u54u71V0vcnU1/zHmrfu6iNt5/7ZREqfjOD2Lz5IRtOsIZIUP4cChFhtyw62S1pIbqDxrkjiNp3CImddKzY2SYgcZ3JYzw3NHnjTDSyMGMYUdTBKIwBrHe5ZeSJsbx5BNkgg2xvP31bFsZ9gIo55fvY7AkTe1ExT6J+hGonaSd1dGMz1y13doMZdKsqR9kxUFZF9hdrO6v7z+fDuDddsGdt6XLU3HP1e3f1z4PwkXqnhDuTQd96XrlkcB/jPx1gFcmi5VofezgwF2n/Mg+PFAOMlSoIKjt/idF6x8X35NHEvbpLG096Vx39AVfdqhXXcF901h1vNdiICNIvc8X4MtlCUJhgxmZik2VNQqjIUtBf67Gp1RFAcjcpqYfHCpCj2TC2PRBqxuoNw8Ss++64t/A3lwxIFVqOkk8h7j6sDaZVEY7e+02h1PWAfLrG2BTEt2yPSwC7QG45X64Ut3sB8lj180NigV5oogG4VxsbOBtcWr2M6CGbnuRBe1c6R5Vlc5ueeHFpAlERTkpaPi2JHu9j5L749sLwiLHWRJ2/4dAAD//yZdRzk/CQAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: /v1, Kind=Service
      objectset.rio.cattle.io/owner-name: traefik
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2025-02-02T14:26:30Z"
    generation: 1
    labels:
      objectset.rio.cattle.io/hash: 836fcbce022d5dae5b36694fe1eaf389c93af7dc
      svccontroller.k3s.cattle.io/nodeselector: "false"
      svccontroller.k3s.cattle.io/svcname: traefik
      svccontroller.k3s.cattle.io/svcnamespace: kube-system
    name: svclb-traefik-64c0d975
    namespace: kube-system
    resourceVersion: "128284"
    uid: ba9b0b21-d86c-4b37-8137-dd3719a4a20e
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: svclb-traefik-64c0d975
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: svclb-traefik-64c0d975
          svccontroller.k3s.cattle.io/svcname: traefik
          svccontroller.k3s.cattle.io/svcnamespace: kube-system
      spec:
        automountServiceAccountToken: false
        containers:
        - env:
          - name: SRC_PORT
            value: "80"
          - name: SRC_RANGES
            value: 0.0.0.0/0
          - name: DEST_PROTO
            value: TCP
          - name: DEST_PORT
            value: "80"
          - name: DEST_IPS
            value: 10.43.42.201
          image: rancher/klipper-lb:v0.4.9
          imagePullPolicy: IfNotPresent
          name: lb-tcp-80
          ports:
          - containerPort: 80
            hostPort: 80
            name: lb-tcp-80
            protocol: TCP
          resources: {}
          securityContext:
            capabilities:
              add:
              - NET_ADMIN
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - env:
          - name: SRC_PORT
            value: "443"
          - name: SRC_RANGES
            value: 0.0.0.0/0
          - name: DEST_PROTO
            value: TCP
          - name: DEST_PORT
            value: "443"
          - name: DEST_IPS
            value: 10.43.42.201
          image: rancher/klipper-lb:v0.4.9
          imagePullPolicy: IfNotPresent
          name: lb-tcp-443
          ports:
          - containerPort: 443
            hostPort: 443
            name: lb-tcp-443
            protocol: TCP
          resources: {}
          securityContext:
            capabilities:
              add:
              - NET_ADMIN
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          sysctls:
          - name: net.ipv4.ip_forward
            value: "1"
        serviceAccount: svclb
        serviceAccountName: svclb
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - key: CriticalAddonsOnly
          operator: Exists
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 2
    desiredNumberScheduled: 2
    numberAvailable: 2
    numberMisscheduled: 0
    numberReady: 2
    observedGeneration: 1
    updatedNumberScheduled: 2
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
      field.cattle.io/publicEndpoints: '[{"nodeName":":ip-172-31-23-7","addresses":["172.31.23.7"],"port":9100,"protocol":"TCP","podName":"monitoring:node-exporter-prometheus-node-exporter-79pzh","allNodes":false},{"nodeName":":ip-172-31-18-33","addresses":["172.31.18.33"],"port":9100,"protocol":"TCP","podName":"monitoring:node-exporter-prometheus-node-exporter-wg5k2","allNodes":false}]'
      meta.helm.sh/release-name: node-exporter
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2025-02-09T06:54:33Z"
    generation: 1
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: node-exporter
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-node-exporter
      app.kubernetes.io/part-of: prometheus-node-exporter
      app.kubernetes.io/version: 1.8.2
      helm.sh/chart: prometheus-node-exporter-4.43.1
    name: node-exporter-prometheus-node-exporter
    namespace: monitoring
    resourceVersion: "128233"
    uid: 3f32c744-b158-428b-819d-32135e07c334
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: node-exporter
        app.kubernetes.io/name: prometheus-node-exporter
    template:
      metadata:
        annotations:
          cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: metrics
          app.kubernetes.io/instance: node-exporter
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: prometheus-node-exporter
          app.kubernetes.io/part-of: prometheus-node-exporter
          app.kubernetes.io/version: 1.8.2
          helm.sh/chart: prometheus-node-exporter-4.43.1
      spec:
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: eks.amazonaws.com/compute-type
                  operator: NotIn
                  values:
                  - fargate
                - key: type
                  operator: NotIn
                  values:
                  - virtual-kubelet
        automountServiceAccountToken: false
        containers:
        - args:
          - --path.procfs=/host/proc
          - --path.sysfs=/host/sys
          - --path.rootfs=/host/root
          - --path.udev.data=/host/root/run/udev/data
          - --web.listen-address=[$(HOST_IP)]:9100
          env:
          - name: HOST_IP
            value: 0.0.0.0
          image: quay.io/prometheus/node-exporter:v1.8.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 9100
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: node-exporter
          ports:
          - containerPort: 9100
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 9100
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /host/proc
            name: proc
            readOnly: true
          - mountPath: /host/sys
            name: sys
            readOnly: true
          - mountPath: /host/root
            mountPropagation: HostToContainer
            name: root
            readOnly: true
        dnsPolicy: ClusterFirst
        hostNetwork: true
        hostPID: true
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
        serviceAccount: node-exporter-prometheus-node-exporter
        serviceAccountName: node-exporter-prometheus-node-exporter
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          operator: Exists
        volumes:
        - hostPath:
            path: /proc
            type: ""
          name: proc
        - hostPath:
            path: /sys
            type: ""
          name: sys
        - hostPath:
            path: /
            type: ""
          name: root
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 2
    desiredNumberScheduled: 2
    numberAvailable: 2
    numberMisscheduled: 0
    numberReady: 2
    observedGeneration: 1
    updatedNumberScheduled: 2
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
    creationTimestamp: "2025-02-06T15:27:39Z"
    generation: 1
    labels:
      component: velero
    name: node-agent
    namespace: velero
    resourceVersion: "128218"
    uid: 13178b61-4c3a-4cec-af1c-f3e6c679e0c2
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        name: node-agent
    template:
      metadata:
        creationTimestamp: null
        labels:
          component: velero
          name: node-agent
      spec:
        containers:
        - args:
          - node-agent
          - server
          - --features=
          command:
          - /velero
          env:
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: VELERO_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: VELERO_SCRATCH_DIR
            value: /scratch
          image: velero/velero:v1.15.2
          imagePullPolicy: IfNotPresent
          name: node-agent
          ports:
          - containerPort: 8085
            name: metrics
            protocol: TCP
          resources: {}
          securityContext:
            privileged: false
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /host_pods
            mountPropagation: HostToContainer
            name: host-pods
          - mountPath: /var/lib/kubelet/plugins
            mountPropagation: HostToContainer
            name: host-plugins
          - mountPath: /scratch
            name: scratch
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          runAsUser: 0
        serviceAccount: velero
        serviceAccountName: velero
        terminationGracePeriodSeconds: 30
        volumes:
        - hostPath:
            path: /var/lib/kubelet/pods
            type: ""
          name: host-pods
        - hostPath:
            path: /var/lib/kubelet/plugins
            type: ""
          name: host-plugins
        - emptyDir: {}
          name: scratch
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 2
    desiredNumberScheduled: 2
    numberAvailable: 2
    numberMisscheduled: 0
    numberReady: 2
    observedGeneration: 1
    updatedNumberScheduled: 2
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "7"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{"management.cattle.io/scale-available":"2"},"name":"cattle-cluster-agent","namespace":"cattle-system"},"spec":{"selector":{"matchLabels":{"app":"cattle-cluster-agent"}},"strategy":{"rollingUpdate":{"maxSurge":1,"maxUnavailable":0},"type":"RollingUpdate"},"template":{"metadata":{"labels":{"app":"cattle-cluster-agent"}},"spec":{"affinity":{"nodeAffinity":{"preferredDuringSchedulingIgnoredDuringExecution":[{"preference":{"matchExpressions":[{"key":"node-role.kubernetes.io/controlplane","operator":"In","values":["true"]}]},"weight":100},{"preference":{"matchExpressions":[{"key":"node-role.kubernetes.io/control-plane","operator":"In","values":["true"]}]},"weight":100},{"preference":{"matchExpressions":[{"key":"node-role.kubernetes.io/master","operator":"In","values":["true"]}]},"weight":100},{"preference":{"matchExpressions":[{"key":"cattle.io/cluster-agent","operator":"In","values":["true"]}]},"weight":1}],"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchExpressions":[{"key":"beta.kubernetes.io/os","operator":"NotIn","values":["windows"]}]}]}},"podAntiAffinity":{"preferredDuringSchedulingIgnoredDuringExecution":[{"podAffinityTerm":{"labelSelector":{"matchExpressions":[{"key":"app","operator":"In","values":["cattle-cluster-agent"]}]},"topologyKey":"kubernetes.io/hostname"},"weight":100}]}},"containers":[{"env":[{"name":"CATTLE_FEATURES","value":"embedded-cluster-api=false,fleet=false,managed-system-upgrade-controller=true,multi-cluster-management=false,multi-cluster-management-agent=true,provisioningprebootstrap=false,provisioningv2=false,rke2=false,ui-sql-cache=false"},{"name":"CATTLE_IS_RKE","value":"false"},{"name":"CATTLE_SERVER","value":"https://44.220.0.65.sslip.io"},{"name":"CATTLE_CA_CHECKSUM","value":""},{"name":"CATTLE_CLUSTER","value":"true"},{"name":"CATTLE_K8S_MANAGED","value":"true"},{"name":"CATTLE_CLUSTER_REGISTRY","value":""},{"name":"CATTLE_SERVER_VERSION","value":"v2.10.2"},{"name":"CATTLE_INSTALL_UUID","value":"dd7c2187-12b9-4774-8ac3-7ac6e676ed0b"},{"name":"CATTLE_INGRESS_IP_DOMAIN","value":"sslip.io"},{"name":"STRICT_VERIFY","value":"false"}],"image":"rancher/rancher-agent:v2.10.2","imagePullPolicy":"IfNotPresent","name":"cluster-register","volumeMounts":[{"mountPath":"/cattle-credentials","name":"cattle-credentials","readOnly":true}]}],"serviceAccountName":"cattle","tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/controlplane","value":"true"},{"effect":"NoSchedule","key":"node-role.kubernetes.io/control-plane","operator":"Exists"},{"effect":"NoSchedule","key":"node-role.kubernetes.io/master","operator":"Exists"}],"volumes":[{"name":"cattle-credentials","secret":{"defaultMode":320,"secretName":"cattle-credentials-8271d07"}}]}}}}
      management.cattle.io/scale-available: "2"
    creationTimestamp: "2025-02-05T01:41:14Z"
    generation: 8
    name: cattle-cluster-agent
    namespace: cattle-system
    resourceVersion: "128366"
    uid: 097c0e51-107e-4f1f-a378-6e2e99ecff42
  spec:
    progressDeadlineSeconds: 600
    replicas: 2
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: cattle-cluster-agent
    strategy:
      rollingUpdate:
        maxSurge: 1
        maxUnavailable: 0
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-02-05T14:24:06Z"
        creationTimestamp: null
        labels:
          app: cattle-cluster-agent
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/controlplane
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/control-plane
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/master
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: cattle.io/cluster-agent
                  operator: In
                  values:
                  - "true"
              weight: 1
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: beta.kubernetes.io/os
                  operator: NotIn
                  values:
                  - windows
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: app
                    operator: In
                    values:
                    - cattle-cluster-agent
                topologyKey: kubernetes.io/hostname
              weight: 100
        containers:
        - env:
          - name: CATTLE_FEATURES
            value: embedded-cluster-api=false,fleet=false,managed-system-upgrade-controller=true,multi-cluster-management=false,multi-cluster-management-agent=true,provisioningprebootstrap=false,provisioningv2=false,rke2=false,ui-sql-cache=false
          - name: CATTLE_IS_RKE
            value: "false"
          - name: CATTLE_SERVER
            value: https://44.220.0.65.sslip.io
          - name: CATTLE_CA_CHECKSUM
          - name: CATTLE_CLUSTER
            value: "true"
          - name: CATTLE_K8S_MANAGED
            value: "true"
          - name: CATTLE_CLUSTER_REGISTRY
          - name: CATTLE_SERVER_VERSION
            value: v2.10.2
          - name: CATTLE_INSTALL_UUID
            value: dd7c2187-12b9-4774-8ac3-7ac6e676ed0b
          - name: CATTLE_INGRESS_IP_DOMAIN
            value: sslip.io
          - name: STRICT_VERIFY
            value: "false"
          image: rancher/rancher-agent:v2.10.2
          imagePullPolicy: IfNotPresent
          name: cluster-register
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /cattle-credentials
            name: cattle-credentials
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: cattle
        serviceAccountName: cattle
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/controlplane
          value: "true"
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - name: cattle-credentials
          secret:
            defaultMode: 320
            secretName: cattle-credentials-8271d07
  status:
    availableReplicas: 2
    conditions:
    - lastTransitionTime: "2025-02-05T01:41:14Z"
      lastUpdateTime: "2025-02-05T14:24:10Z"
      message: ReplicaSet "cattle-cluster-agent-55dd5f54bb" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-03-03T02:56:42Z"
      lastUpdateTime: "2025-03-03T02:56:42Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 8
    readyReplicas: 2
    replicas: 2
    updatedReplicas: 2
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: rancher-webhook
      meta.helm.sh/release-namespace: cattle-system
    creationTimestamp: "2025-02-05T14:26:51Z"
    generation: 1
    labels:
      app.kubernetes.io/managed-by: Helm
    name: rancher-webhook
    namespace: cattle-system
    resourceVersion: "128231"
    uid: 52e5e943-424d-4926-b1cb-3f7f8ebdd610
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: rancher-webhook
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: rancher-webhook
      spec:
        containers:
        - env:
          - name: STAMP
          - name: ENABLE_MCM
            value: "false"
          - name: CATTLE_PORT
            value: "9443"
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: rancher/rancher-webhook:v0.6.3
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: https
              scheme: HTTPS
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          name: rancher-webhook
          ports:
          - containerPort: 9443
            name: https
            protocol: TCP
          resources: {}
          startupProbe:
            failureThreshold: 60
            httpGet:
              path: /healthz
              port: https
              scheme: HTTPS
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: rancher-webhook
        serviceAccountName: rancher-webhook
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: cattle.io/os
          operator: Equal
          value: linux
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-02-05T14:26:51Z"
      lastUpdateTime: "2025-02-05T14:27:12Z"
      message: ReplicaSet "rancher-webhook-586f888bb" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-03-03T02:55:20Z"
      lastUpdateTime: "2025-03-03T02:55:20Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: system-upgrade-controller
      meta.helm.sh/release-namespace: cattle-system
    creationTimestamp: "2025-02-05T14:25:40Z"
    generation: 1
    labels:
      app.kubernetes.io/managed-by: Helm
    name: system-upgrade-controller
    namespace: cattle-system
    resourceVersion: "115770"
    uid: 33eedbe4-b0db-477a-b2cb-3fda3315857c
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        upgrade.cattle.io/controller: system-upgrade-controller
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          upgrade.cattle.io/controller: system-upgrade-controller
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/control-plane
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/master
                  operator: In
                  values:
                  - "true"
              weight: 100
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: kubernetes.io/os
                  operator: NotIn
                  values:
                  - windows
        containers:
        - env:
          - name: SYSTEM_UPGRADE_CONTROLLER_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['upgrade.cattle.io/controller']
          - name: SYSTEM_UPGRADE_CONTROLLER_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          envFrom:
          - configMapRef:
              name: system-upgrade-controller-config
          image: rancher/system-upgrade-controller:v0.14.2
          imagePullPolicy: IfNotPresent
          name: system-upgrade-controller
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            runAsGroup: 65534
            runAsNonRoot: true
            runAsUser: 65534
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/ssl
            name: etc-ssl
            readOnly: true
          - mountPath: /etc/pki
            name: etc-pki
            readOnly: true
          - mountPath: /etc/ca-certificates
            name: etc-ca-certificates
            readOnly: true
          - mountPath: /tmp
            name: tmp
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: system-upgrade-controller
        serviceAccountName: system-upgrade-controller
        terminationGracePeriodSeconds: 30
        tolerations:
        - operator: Exists
        volumes:
        - hostPath:
            path: /etc/ssl
            type: DirectoryOrCreate
          name: etc-ssl
        - hostPath:
            path: /etc/pki
            type: DirectoryOrCreate
          name: etc-pki
        - hostPath:
            path: /etc/ca-certificates
            type: DirectoryOrCreate
          name: etc-ca-certificates
        - emptyDir: {}
          name: tmp
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-02-05T14:25:40Z"
      lastUpdateTime: "2025-02-05T14:25:42Z"
      message: ReplicaSet "system-upgrade-controller-5fb67f585d" has successfully
        progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-03-02T08:06:28Z"
      lastUpdateTime: "2025-03-02T08:06:28Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "10"
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/6xVQW/bOBP9Kx/mLMVW0jaugO/QjbPboq3XqJNeiqCgqZHFNcXhkiMnRqD/vhhJduw2TdrFniyTb4ZvHucN70F58xlDNOQgB+V9HG0ySGBtXAE5TNFb2tboGBKokVWhWEF+D8o5YsWGXJS/tPwLNUfkk2DoRCtmiyeGRkaSQPLDfbp1GNLVZg05rM/iwc4mS/733rji/2+KgtyzKZyqEXLQFLBw8afg0SstMetmiWncRsYa2gSsWqLtilpPYqq830H6vPIZHDJGyTYce0EBp7PFE8dWKlaQw1Lj6eTs9PVkkmXnL87U+GzySi1fZuPytHx1juX5i9MXY/3yXIh8V9ITpKNHLZQDbozc5VsTmcL2g6kNQz5OIKJFzRQEVCvW1YenymwlJQfFuNp2acla41bXvlCMfYq7a6c2yli1tAh51ibAWy/MPh1hZR1rb3dxBy30pNDtQVGaHCvjMETIv9yDCiv5gFSTKyGBEbIeDSqN5CZKYxFuEjC1WgmjoJyuMIxqE4LA0gG8+82zk+z0ZAxDxLyxdk7W6C3k8K6cEc8Dxt4C1mzQYYzzQMuuoFIZ2wS8qgLGimwB+VkCFbP/A1n2vWK591GFynIFCXgKDPlkPJFL0RV2d/z26mouUhln2Cg7Rau2C9Tkigj5q3ECHoOhYr+USXCjNcZ4cHKWAJsaqeEH4GN9JBR6KffKzjtWL8/26AEZiEmThRyup8LwmZCUtT8Ou7p4NOx1dhBYIwej4yOBNwkEVIX5V5JL5PZB8WyS/azi3wt++gt6B4zUBI1da1txYOxbv6YgLZWdjz8a6IB/Nxj7Xe0b2RqP627QDtAeKVZA3QTD2wtyjHddmcpaup0HszEWV3gZtbLdPIa8VDZiAlp5tTTWsOmpqKIQ28wur77+9m42/bq4/PT53cWlOKUI5GVPWQs3bS/6n85uPxHx78biMGhyDg22CWzINjV+pMYNfVTL53zQ/cCOcNB9rjSrtI+EhxN2OX+cY6SbyFQfpOr+p89kvJHmKVzcO3mKpWqsmNhRgYuDeXg80ilCDta45k7uyAdDnfBWxTjrCfRqpNo2kTGkOhg2WlmQawobo/GN1lLM7FvjMVkMu0fzyz2sUYhdDPHdQxe7EhIgL0jhB5d3RppENMKyRM2Qw4wWusKisVJ5n0aqSgNZPDmuR5wXyKbeKof/aeZaSf2Pp7yRaj1ZWm0XXq7mgpy8KGbXMt30X/zyq1Sru8Uab3vzDQe871gec6soctcvCdxW6K5dVGxiafrnCqY0I94XKmz7PtqPxdKsPiovRAxjfXRduxcm2U2a/YoI2YNmVOBbEiX2qIclOe6bodz+wCjD6HxgcxyX7r1BXtpK2b1HnzJLe9O2bftPAAAA//8kyNqv/AkAAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: k3s.cattle.io/v1, Kind=Addon
      objectset.rio.cattle.io/owner-name: coredns
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2025-02-02T14:26:17Z"
    generation: 10
    labels:
      k8s-app: kube-dns
      kubernetes.io/name: CoreDNS
      objectset.rio.cattle.io/hash: bce283298811743a0386ab510f2f67ef74240c57
    name: coredns
    namespace: kube-system
    resourceVersion: "115780"
    uid: 1c1b9020-d7ff-4877-bce4-3243352e62bf
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 0
    selector:
      matchLabels:
        k8s-app: kube-dns
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-02-05T14:24:18Z"
        creationTimestamp: null
        labels:
          k8s-app: kube-dns
      spec:
        containers:
        - args:
          - -conf
          - /etc/coredns/Corefile
          image: rancher/mirrored-coredns-coredns:1.12.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /health
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: coredns
          ports:
          - containerPort: 53
            name: dns
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 9153
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: 8181
              scheme: HTTP
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - all
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/coredns
            name: config-volume
            readOnly: true
          - mountPath: /etc/coredns/custom
            name: custom-config-volume
            readOnly: true
        dnsPolicy: Default
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: coredns
        serviceAccountName: coredns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        topologySpreadConstraints:
        - labelSelector:
            matchLabels:
              k8s-app: kube-dns
          maxSkew: 1
          topologyKey: kubernetes.io/hostname
          whenUnsatisfiable: DoNotSchedule
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: Corefile
              path: Corefile
            - key: NodeHosts
              path: NodeHosts
            name: coredns
          name: config-volume
        - configMap:
            defaultMode: 420
            name: coredns-custom
            optional: true
          name: custom-config-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-02-02T14:26:20Z"
      lastUpdateTime: "2025-02-02T14:26:20Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-02-02T14:26:20Z"
      lastUpdateTime: "2025-02-05T14:24:19Z"
      message: ReplicaSet "coredns-8544b8dd7b" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 10
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/6xUXWvrRhD9K2WeJdmuE2MEfTBJSksTxySkL8GU8Wpkb7zaXXbHaoTRf7+MJeeDGyf3wn3SfsycPTPnjPaAXv9LIWpnIQf0Pg7qESSw1baAHC7JG9dUZBkSqIixQEbI94DWOkbWzkbZutUTKY7EWdAuU8hsKNNuoAUEkpP37n9LIV3XW8hhO45vbupR8ts/2hZ/zIrC2S8hLFYEORin0KSRXcA1/VBS9Kgkc7tbURqbyFRBm4DBFZlPS9tg3EAOo+m4HJ+ryXlZrtR4ODmbDMfl2bgcnU+HxVRNpvh7gaviTEDfkfTIm9QHV2tpPgXo7k/wiZ6UsAnUxf+lpcjmWleaIR8mEMmQYhckqEJWm+uXCtD706+2As4BmdbN4QFnjLbrB18gUwf2/GCxRm1wZQjyUZsAN1443r2LlXOqvDnmvXGL+QkufaHKWUZtKUTIH2VbVSiWfDzdvsgYxKdpqpwt9RoSGBCrQbfrP9lTdBaWCZCtD8i9KIvby//ms5ur+8Xs4goSqNHs6M/gKiFTajLFHZUv6wWyiH+sMXtVrm3bZQK6Ev/lENCqDYXBx5zzepgNs/EQ+oTFzpiFM1o1kMPf5dzxIlDshu8r79TO7Cq6cTvLXccqWfY837bhFas7SLtMaJdC3AftgubmwmCM8y6uc2FqXUGpCpq1QiPtplBrRTOl5KX5Z/zSPjbFLhgSYGcoHH8gj3vYkhR90cMfhj7eWtPIEHuJFGvD1bOOHKFN9kBlSYohh7m7VxsqdkYGvoM5UA3OUCZjFCwxRZlZMVVwJvUGLf1S5AojH3T4AHJ5VOdoZWn7DXpx0/ey9t5tT8vUtu23AAAA///s6eu+uAUAAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: k3s.cattle.io/v1, Kind=Addon
      objectset.rio.cattle.io/owner-name: local-storage
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2025-02-02T14:26:17Z"
    generation: 1
    labels:
      objectset.rio.cattle.io/hash: 183f35c65ffbc3064603f43f1580d8c68a2dabd4
    name: local-path-provisioner
    namespace: kube-system
    resourceVersion: "115746"
    uid: fc801ef2-1c56-48f8-918d-8a6055db4094
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 0
    selector:
      matchLabels:
        app: local-path-provisioner
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: local-path-provisioner
      spec:
        containers:
        - command:
          - local-path-provisioner
          - start
          - --config
          - /etc/config/config.json
          env:
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: rancher/local-path-provisioner:v0.0.30
          imagePullPolicy: IfNotPresent
          name: local-path-provisioner
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config/
            name: config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: local-path-provisioner-service-account
        serviceAccountName: local-path-provisioner-service-account
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: local-path-config
          name: config-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-02-02T14:26:20Z"
      lastUpdateTime: "2025-02-02T14:26:20Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-02-02T14:26:20Z"
      lastUpdateTime: "2025-02-02T14:26:25Z"
      message: ReplicaSet "local-path-provisioner-5cf85fd84d" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/6xV4W8auRP9V36az7vJLoHQrsQHRPiV6tIUFXqnUxUh4x3Ah9f2eWZpuIj//TS7SUovpelV9wUt9vPzmzfjmXtQwfyKkYx3UIAKgc53OSSwNa6EAq4wWL+v0DEkUCGrUrGC4h6Uc54VG+9I/vrlH6iZkM+i8WdaMVs8M/7cCAkkJ/f9Z4cxXe+2UMD2go52dnnyv1+MKwfDsvTuRQqnKoRCJEajKSWMO4xpeSz/ZQIKSgvLtl5iSntirOCQgFVLtE2Y21eUqhCeXfQd9o2iDRSAeYadbg/zC+xeqn6np1+XZVl2V69x2bl4vcq7/X6/uyrlvm/GAu36CYkUUIvAiDsjuZwYYh/316YyDEWWAKFFzT4KqFKsN9cvB3UQYo6Kcb1vyL21xq0/hlIxtkR3H53aKWPV0iIU+SEB3gfR9+ErrKxjFezjuaNC+gFzT1pyFLj2jpVxGAmKT/eg4lo+IE01Rk5LEwfnXAVIIE0JdR0xDT7yIM86vaxZFUMtchoirjBGLFNVlhGJUomIBm8dY3TKvp0m47unz4knbrQdU9SEqfMlpsSKa2puagCt/DQieVvL2xnkPWp22FKqTdhgTKk2jDSYX88W49HVZCy/s+Hit7fzyWI4ni06vcvFm9G7xWwyvHjVTb7gPvwQ6h9seefVI67TuzzFdhJ1xDaaDEeTYSdbTN9f/55fZL1vkT0DwW0CplJryW5UTm8wnlcmRi8Z+DrdxS476591IAFrduiQaBr9simolTK2jjjfRKSNtyUUFwlsmMMbZNkPiuURnsvBvyCBJiNFgxD/SW+wqa/JfD6dSVkZZ9goe4VW7WeovSsJisssgYDR+PJpKZenVWuNREeX5wmwqdDX/AX4nXctatqyfariaSOwqc6nc49qQ/TstbdQwHw0hcNtAhFVaX7KETm5/3lLnjvS+ReGyEOoo0ZqW9efNRI33zrUUECeZVUzdiof91BAP3tn2qYkL9jwfuQd410Tj7LWf55GszMW1zgmrWwznaBYKUvYWvTe2f0H7/n/xuJD7yw41rJbuyHdeCe7X619JIySiCw7JLDztq7wna/dQ74q+Zw+WNn2l4dkcRWk68DhVvITovGNYKuIblpEK6BtFDoaNlpZMR7jzmgcai3cNydKhr3F+Dh+P93DFsWg0QNNMzJJopXBFAQpnR/Gd0YMPiT3gKsVakn4jZ/pDZa1lR7W0jSSord4Jh0tOmQkGWVSndHbNFjl8D9lrhRxO0WfU94++t5GilXg/ZWRQXb4ltuHw+HvAAAA//9PFN5y1QgAAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: k3s.cattle.io/v1, Kind=Addon
      objectset.rio.cattle.io/owner-name: metrics-server-deployment
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2025-02-02T14:26:18Z"
    generation: 1
    labels:
      k8s-app: metrics-server
      objectset.rio.cattle.io/hash: e10e245e13e46a725c9dddd4f9eb239f147774fd
    name: metrics-server
    namespace: kube-system
    resourceVersion: "128241"
    uid: ef8c123e-bb01-46a8-aa98-61da6c93a682
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 0
    selector:
      matchLabels:
        k8s-app: metrics-server
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: metrics-server
        name: metrics-server
      spec:
        containers:
        - args:
          - --cert-dir=/tmp
          - --secure-port=10250
          - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
          - --kubelet-use-node-status-port
          - --metric-resolution=15s
          - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305
          image: rancher/mirrored-metrics-server:v0.7.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /livez
              port: https
              scheme: HTTPS
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: metrics-server
          ports:
          - containerPort: 10250
            name: https
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: https
              scheme: HTTPS
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp
            name: tmp-dir
        dnsPolicy: ClusterFirst
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metrics-server
        serviceAccountName: metrics-server
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - emptyDir: {}
          name: tmp-dir
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-02-02T14:26:20Z"
      lastUpdateTime: "2025-02-02T14:26:20Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-02-02T14:26:20Z"
      lastUpdateTime: "2025-02-02T14:26:43Z"
      message: ReplicaSet "metrics-server-5985cbc9d7" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      field.cattle.io/publicEndpoints: '[{"addresses":["172.31.18.33","172.31.23.7"],"port":80,"protocol":"TCP","serviceName":"kube-system:traefik","allNodes":false},{"addresses":["172.31.18.33","172.31.23.7"],"port":443,"protocol":"TCP","serviceName":"kube-system:traefik","allNodes":false}]'
      meta.helm.sh/release-name: traefik
      meta.helm.sh/release-namespace: kube-system
    creationTimestamp: "2025-02-02T14:26:30Z"
    generation: 8
    labels:
      app.kubernetes.io/instance: traefik-kube-system
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: traefik
      helm.sh/chart: traefik-27.0.201_up27.0.2
    name: traefik
    namespace: kube-system
    resourceVersion: "115826"
    uid: d9dd6749-759a-41dd-93d1-b43c038801e2
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: traefik-kube-system
        app.kubernetes.io/name: traefik
    strategy:
      rollingUpdate:
        maxSurge: 1
        maxUnavailable: 0
      type: RollingUpdate
    template:
      metadata:
        annotations:
          prometheus.io/path: /metrics
          prometheus.io/port: "9100"
          prometheus.io/scrape: "true"
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: traefik-kube-system
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: traefik
          helm.sh/chart: traefik-27.0.201_up27.0.2
      spec:
        containers:
        - args:
          - --global.checknewversion
          - --global.sendanonymoususage
          - --entrypoints.metrics.address=:9100/tcp
          - --entrypoints.traefik.address=:9000/tcp
          - --entrypoints.web.address=:8000/tcp
          - --entrypoints.websecure.address=:8443/tcp
          - --api.dashboard=true
          - --ping=true
          - --metrics.prometheus=true
          - --metrics.prometheus.entrypoint=metrics
          - --providers.kubernetescrd
          - --providers.kubernetesingress
          - --providers.kubernetesingress.ingressendpoint.publishedservice=kube-system/traefik
          - --entrypoints.websecure.http.tls=true
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: rancher/mirrored-library-traefik:2.11.18
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /ping
              port: 9000
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          name: traefik
          ports:
          - containerPort: 9100
            name: metrics
            protocol: TCP
          - containerPort: 9000
            name: traefik
            protocol: TCP
          - containerPort: 8000
            name: web
            protocol: TCP
          - containerPort: 8443
            name: websecure
            protocol: TCP
          readinessProbe:
            failureThreshold: 1
            httpGet:
              path: /ping
              port: 9000
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /data
            name: data
          - mountPath: /tmp
            name: tmp
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroupChangePolicy: OnRootMismatch
          runAsGroup: 65532
          runAsNonRoot: true
          runAsUser: 65532
        serviceAccount: traefik
        serviceAccountName: traefik
        terminationGracePeriodSeconds: 60
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - emptyDir: {}
          name: data
        - emptyDir: {}
          name: tmp
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-02-02T14:26:30Z"
      lastUpdateTime: "2025-02-02T14:26:40Z"
      message: ReplicaSet "traefik-5d45fc8cc9" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-03-02T08:06:30Z"
      lastUpdateTime: "2025-03-02T08:06:30Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 8
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      field.cattle.io/publicEndpoints: '[{"port":30088,"protocol":"TCP","serviceName":"nginx:nginx-service","allNodes":true}]'
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"name":"nginx-deployment","namespace":"nginx"},"spec":{"replicas":2,"selector":{"matchLabels":{"app":"nginx"}},"template":{"metadata":{"labels":{"app":"nginx"}},"spec":{"containers":[{"image":"nginx:latest","name":"nginx","ports":[{"containerPort":80}]}]}}}}
    creationTimestamp: "2025-02-11T12:36:08Z"
    generation: 4
    name: nginx-deployment
    namespace: nginx
    resourceVersion: "128110"
    uid: 0d3eff49-f2e1-4c9b-ae7c-b2ed21d3564e
  spec:
    progressDeadlineSeconds: 600
    replicas: 2
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: nginx
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: nginx
      spec:
        containers:
        - image: nginx:latest
          imagePullPolicy: Always
          name: nginx
          ports:
          - containerPort: 80
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 2
    conditions:
    - lastTransitionTime: "2025-02-11T12:36:08Z"
      lastUpdateTime: "2025-02-11T12:36:13Z"
      message: ReplicaSet "nginx-deployment-54b9c68f67" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-03-03T02:55:08Z"
      lastUpdateTime: "2025-03-03T02:55:08Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 4
    readyReplicas: 2
    replicas: 2
    updatedReplicas: 2
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "3"
    creationTimestamp: "2025-02-06T15:27:39Z"
    generation: 3
    labels:
      component: velero
    name: velero
    namespace: velero
    resourceVersion: "128172"
    uid: 27f1d208-f1e3-4f0b-a641-d4648812cf24
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        deploy: velero
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-02-09T06:08:17Z"
          prometheus.io/path: /metrics
          prometheus.io/port: "8085"
          prometheus.io/scrape: "true"
        creationTimestamp: null
        labels:
          component: velero
          deploy: velero
      spec:
        containers:
        - args:
          - server
          - --features=
          - --uploader-type=kopia
          command:
          - /velero
          env:
          - name: VELERO_SCRATCH_DIR
            value: /scratch
          - name: VELERO_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: LD_LIBRARY_PATH
            value: /plugins
          image: velero/velero:v1.15.2
          imagePullPolicy: IfNotPresent
          name: velero
          ports:
          - containerPort: 8085
            name: metrics
            protocol: TCP
          resources:
            limits:
              cpu: "1"
              memory: 512Mi
            requests:
              cpu: 500m
              memory: 128Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /plugins
            name: plugins
          - mountPath: /scratch
            name: scratch
        dnsPolicy: Default
        initContainers:
        - image: velero/velero-plugin-for-aws:v1.10.0
          imagePullPolicy: IfNotPresent
          name: velero-velero-plugin-for-aws
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /target
            name: plugins
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: velero
        serviceAccountName: velero
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: plugins
        - emptyDir: {}
          name: scratch
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-02-06T15:27:39Z"
      lastUpdateTime: "2025-02-09T06:08:20Z"
      message: ReplicaSet "velero-5844478ff5" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-03-03T02:55:09Z"
      lastUpdateTime: "2025-03-03T02:55:09Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 3
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "5"
      management.cattle.io/scale-available: "2"
    creationTimestamp: "2025-02-05T14:23:54Z"
    generation: 2
    labels:
      app: cattle-cluster-agent
      pod-template-hash: 54578f7fbd
    name: cattle-cluster-agent-54578f7fbd
    namespace: cattle-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: cattle-cluster-agent
      uid: 097c0e51-107e-4f1f-a378-6e2e99ecff42
    resourceVersion: "55777"
    uid: db9b5d82-58b3-48f9-9615-6cf34aecec8e
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: cattle-cluster-agent
        pod-template-hash: 54578f7fbd
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-02-05T02:06:19Z"
        creationTimestamp: null
        labels:
          app: cattle-cluster-agent
          pod-template-hash: 54578f7fbd
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/controlplane
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/control-plane
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/master
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: cattle.io/cluster-agent
                  operator: In
                  values:
                  - "true"
              weight: 1
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: beta.kubernetes.io/os
                  operator: NotIn
                  values:
                  - windows
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: app
                    operator: In
                    values:
                    - cattle-cluster-agent
                topologyKey: kubernetes.io/hostname
              weight: 100
        containers:
        - env:
          - name: CATTLE_FEATURES
            value: embedded-cluster-api=false,fleet=false,managed-system-upgrade-controller=false,multi-cluster-management=false,multi-cluster-management-agent=true,provisioningprebootstrap=false,provisioningv2=false,rke2=false,ui-sql-cache=false
          - name: CATTLE_IS_RKE
            value: "false"
          - name: CATTLE_SERVER
            value: https://44.220.0.65.sslip.io
          - name: CATTLE_CA_CHECKSUM
          - name: CATTLE_CLUSTER
            value: "true"
          - name: CATTLE_K8S_MANAGED
            value: "true"
          - name: CATTLE_CLUSTER_REGISTRY
          - name: CATTLE_SERVER_VERSION
            value: v2.10.2
          - name: CATTLE_INSTALL_UUID
            value: dd7c2187-12b9-4774-8ac3-7ac6e676ed0b
          - name: CATTLE_INGRESS_IP_DOMAIN
            value: sslip.io
          - name: STRICT_VERIFY
            value: "false"
          image: rancher/rancher-agent:v2.10.2
          imagePullPolicy: IfNotPresent
          name: cluster-register
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /cattle-credentials
            name: cattle-credentials
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: cattle
        serviceAccountName: cattle
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/controlplane
          value: "true"
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - name: cattle-credentials
          secret:
            defaultMode: 320
            secretName: cattle-credentials-8271d07
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "4"
      management.cattle.io/scale-available: "2"
    creationTimestamp: "2025-02-05T14:23:39Z"
    generation: 2
    labels:
      app: cattle-cluster-agent
      pod-template-hash: 559975ddc8
    name: cattle-cluster-agent-559975ddc8
    namespace: cattle-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: cattle-cluster-agent
      uid: 097c0e51-107e-4f1f-a378-6e2e99ecff42
    resourceVersion: "55743"
    uid: 7ba2e445-006f-4557-b023-066eeaa78783
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: cattle-cluster-agent
        pod-template-hash: 559975ddc8
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-02-05T02:06:19Z"
        creationTimestamp: null
        labels:
          app: cattle-cluster-agent
          pod-template-hash: 559975ddc8
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/controlplane
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/control-plane
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/master
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: cattle.io/cluster-agent
                  operator: In
                  values:
                  - "true"
              weight: 1
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: beta.kubernetes.io/os
                  operator: NotIn
                  values:
                  - windows
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: app
                    operator: In
                    values:
                    - cattle-cluster-agent
                topologyKey: kubernetes.io/hostname
              weight: 100
        containers:
        - env:
          - name: CATTLE_IS_RKE
            value: "false"
          - name: CATTLE_SERVER
            value: https://44.220.0.65.sslip.io
          - name: CATTLE_CA_CHECKSUM
          - name: CATTLE_CLUSTER
            value: "true"
          - name: CATTLE_K8S_MANAGED
            value: "true"
          - name: CATTLE_CLUSTER_REGISTRY
          - name: CATTLE_SERVER_VERSION
            value: v2.10.2
          - name: CATTLE_INSTALL_UUID
            value: dd7c2187-12b9-4774-8ac3-7ac6e676ed0b
          - name: CATTLE_INGRESS_IP_DOMAIN
            value: sslip.io
          - name: STRICT_VERIFY
            value: "false"
          image: rancher/rancher-agent:v2.10.2
          imagePullPolicy: IfNotPresent
          name: cluster-register
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /cattle-credentials
            name: cattle-credentials
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: cattle
        serviceAccountName: cattle
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/controlplane
          value: "true"
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - name: cattle-credentials
          secret:
            defaultMode: 320
            secretName: cattle-credentials-0c5d110
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "2"
      management.cattle.io/scale-available: "2"
    creationTimestamp: "2025-02-05T02:06:19Z"
    generation: 2
    labels:
      app: cattle-cluster-agent
      pod-template-hash: 55db575df4
    name: cattle-cluster-agent-55db575df4
    namespace: cattle-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: cattle-cluster-agent
      uid: 097c0e51-107e-4f1f-a378-6e2e99ecff42
    resourceVersion: "48768"
    uid: 8b34dd9d-066d-47ae-939a-2098da84d6e9
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: cattle-cluster-agent
        pod-template-hash: 55db575df4
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-02-05T02:06:19Z"
        creationTimestamp: null
        labels:
          app: cattle-cluster-agent
          pod-template-hash: 55db575df4
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/controlplane
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/control-plane
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/master
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: cattle.io/cluster-agent
                  operator: In
                  values:
                  - "true"
              weight: 1
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: beta.kubernetes.io/os
                  operator: NotIn
                  values:
                  - windows
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: app
                    operator: In
                    values:
                    - cattle-cluster-agent
                topologyKey: kubernetes.io/hostname
              weight: 100
        containers:
        - env:
          - name: CATTLE_IS_RKE
            value: "false"
          - name: CATTLE_SERVER
            value: https://44.220.0.65.sslip.io:31403
          - name: CATTLE_CA_CHECKSUM
            value: 3338fce4f2e16671ae970ccb2edb41e59f7c7d5020a76994f60b32ef81acfdda
          - name: CATTLE_CLUSTER
            value: "true"
          - name: CATTLE_K8S_MANAGED
            value: "true"
          - name: CATTLE_CLUSTER_REGISTRY
          - name: CATTLE_SERVER_VERSION
            value: v2.10.2
          - name: CATTLE_INSTALL_UUID
            value: 4d5708cf-c9b5-471e-a07a-95da83c2e32f
          - name: CATTLE_INGRESS_IP_DOMAIN
            value: sslip.io
          - name: STRICT_VERIFY
            value: "false"
          image: rancher/rancher-agent:v2.10.2
          imagePullPolicy: IfNotPresent
          name: cluster-register
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /cattle-credentials
            name: cattle-credentials
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: cattle
        serviceAccountName: cattle
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/controlplane
          value: "true"
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - name: cattle-credentials
          secret:
            defaultMode: 320
            secretName: cattle-credentials-cc48e3e
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "2"
      deployment.kubernetes.io/max-replicas: "3"
      deployment.kubernetes.io/revision: "7"
      management.cattle.io/scale-available: "2"
    creationTimestamp: "2025-02-05T14:24:06Z"
    generation: 2
    labels:
      app: cattle-cluster-agent
      pod-template-hash: 55dd5f54bb
    name: cattle-cluster-agent-55dd5f54bb
    namespace: cattle-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: cattle-cluster-agent
      uid: 097c0e51-107e-4f1f-a378-6e2e99ecff42
    resourceVersion: "128365"
    uid: 2bb122d9-06a2-49f2-96fe-f264fc401428
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: cattle-cluster-agent
        pod-template-hash: 55dd5f54bb
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-02-05T14:24:06Z"
        creationTimestamp: null
        labels:
          app: cattle-cluster-agent
          pod-template-hash: 55dd5f54bb
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/controlplane
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/control-plane
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/master
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: cattle.io/cluster-agent
                  operator: In
                  values:
                  - "true"
              weight: 1
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: beta.kubernetes.io/os
                  operator: NotIn
                  values:
                  - windows
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: app
                    operator: In
                    values:
                    - cattle-cluster-agent
                topologyKey: kubernetes.io/hostname
              weight: 100
        containers:
        - env:
          - name: CATTLE_FEATURES
            value: embedded-cluster-api=false,fleet=false,managed-system-upgrade-controller=true,multi-cluster-management=false,multi-cluster-management-agent=true,provisioningprebootstrap=false,provisioningv2=false,rke2=false,ui-sql-cache=false
          - name: CATTLE_IS_RKE
            value: "false"
          - name: CATTLE_SERVER
            value: https://44.220.0.65.sslip.io
          - name: CATTLE_CA_CHECKSUM
          - name: CATTLE_CLUSTER
            value: "true"
          - name: CATTLE_K8S_MANAGED
            value: "true"
          - name: CATTLE_CLUSTER_REGISTRY
          - name: CATTLE_SERVER_VERSION
            value: v2.10.2
          - name: CATTLE_INSTALL_UUID
            value: dd7c2187-12b9-4774-8ac3-7ac6e676ed0b
          - name: CATTLE_INGRESS_IP_DOMAIN
            value: sslip.io
          - name: STRICT_VERIFY
            value: "false"
          image: rancher/rancher-agent:v2.10.2
          imagePullPolicy: IfNotPresent
          name: cluster-register
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /cattle-credentials
            name: cattle-credentials
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: cattle
        serviceAccountName: cattle
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/controlplane
          value: "true"
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - name: cattle-credentials
          secret:
            defaultMode: 320
            secretName: cattle-credentials-8271d07
  status:
    availableReplicas: 2
    fullyLabeledReplicas: 2
    observedGeneration: 2
    readyReplicas: 2
    replicas: 2
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "3"
      management.cattle.io/scale-available: "2"
    creationTimestamp: "2025-02-05T05:42:31Z"
    generation: 2
    labels:
      app: cattle-cluster-agent
      pod-template-hash: 5d44ff866c
    name: cattle-cluster-agent-5d44ff866c
    namespace: cattle-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: cattle-cluster-agent
      uid: 097c0e51-107e-4f1f-a378-6e2e99ecff42
    resourceVersion: "55550"
    uid: f68f0864-922c-42f2-b039-69b60e4a4846
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: cattle-cluster-agent
        pod-template-hash: 5d44ff866c
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-02-05T02:06:19Z"
        creationTimestamp: null
        labels:
          app: cattle-cluster-agent
          pod-template-hash: 5d44ff866c
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/controlplane
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/control-plane
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/master
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: cattle.io/cluster-agent
                  operator: In
                  values:
                  - "true"
              weight: 1
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: beta.kubernetes.io/os
                  operator: NotIn
                  values:
                  - windows
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: app
                    operator: In
                    values:
                    - cattle-cluster-agent
                topologyKey: kubernetes.io/hostname
              weight: 100
        containers:
        - env:
          - name: CATTLE_IS_RKE
            value: "false"
          - name: CATTLE_SERVER
            value: https://44.220.0.65.sslip.io
          - name: CATTLE_CA_CHECKSUM
          - name: CATTLE_CLUSTER
            value: "true"
          - name: CATTLE_K8S_MANAGED
            value: "true"
          - name: CATTLE_CLUSTER_REGISTRY
          - name: CATTLE_SERVER_VERSION
            value: v2.10.2
          - name: CATTLE_INSTALL_UUID
            value: dd7c2187-12b9-4774-8ac3-7ac6e676ed0b
          - name: CATTLE_INGRESS_IP_DOMAIN
            value: sslip.io
          - name: STRICT_VERIFY
            value: "true"
          image: rancher/rancher-agent:v2.10.2
          imagePullPolicy: IfNotPresent
          name: cluster-register
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /cattle-credentials
            name: cattle-credentials
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: cattle
        serviceAccountName: cattle
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/controlplane
          value: "true"
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - name: cattle-credentials
          secret:
            defaultMode: 320
            secretName: cattle-credentials-0c5d110
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "2"
      deployment.kubernetes.io/max-replicas: "3"
      deployment.kubernetes.io/revision: "6"
      management.cattle.io/scale-available: "2"
    creationTimestamp: "2025-02-05T14:23:57Z"
    generation: 2
    labels:
      app: cattle-cluster-agent
      pod-template-hash: 69855f9bb9
    name: cattle-cluster-agent-69855f9bb9
    namespace: cattle-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: cattle-cluster-agent
      uid: 097c0e51-107e-4f1f-a378-6e2e99ecff42
    resourceVersion: "56152"
    uid: 325d5279-7111-441f-863c-61801398c32c
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: cattle-cluster-agent
        pod-template-hash: 69855f9bb9
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-02-05T02:06:19Z"
        creationTimestamp: null
        labels:
          app: cattle-cluster-agent
          pod-template-hash: 69855f9bb9
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/controlplane
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/control-plane
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/master
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: cattle.io/cluster-agent
                  operator: In
                  values:
                  - "true"
              weight: 1
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: beta.kubernetes.io/os
                  operator: NotIn
                  values:
                  - windows
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: app
                    operator: In
                    values:
                    - cattle-cluster-agent
                topologyKey: kubernetes.io/hostname
              weight: 100
        containers:
        - env:
          - name: CATTLE_FEATURES
            value: embedded-cluster-api=false,fleet=false,managed-system-upgrade-controller=true,multi-cluster-management=false,multi-cluster-management-agent=true,provisioningprebootstrap=false,provisioningv2=false,rke2=false,ui-sql-cache=false
          - name: CATTLE_IS_RKE
            value: "false"
          - name: CATTLE_SERVER
            value: https://44.220.0.65.sslip.io
          - name: CATTLE_CA_CHECKSUM
          - name: CATTLE_CLUSTER
            value: "true"
          - name: CATTLE_K8S_MANAGED
            value: "true"
          - name: CATTLE_CLUSTER_REGISTRY
          - name: CATTLE_SERVER_VERSION
            value: v2.10.2
          - name: CATTLE_INSTALL_UUID
            value: dd7c2187-12b9-4774-8ac3-7ac6e676ed0b
          - name: CATTLE_INGRESS_IP_DOMAIN
            value: sslip.io
          - name: STRICT_VERIFY
            value: "false"
          image: rancher/rancher-agent:v2.10.2
          imagePullPolicy: IfNotPresent
          name: cluster-register
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /cattle-credentials
            name: cattle-credentials
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: cattle
        serviceAccountName: cattle
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/controlplane
          value: "true"
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - name: cattle-credentials
          secret:
            defaultMode: 320
            secretName: cattle-credentials-8271d07
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      management.cattle.io/scale-available: "2"
    creationTimestamp: "2025-02-05T01:41:14Z"
    generation: 2
    labels:
      app: cattle-cluster-agent
      pod-template-hash: 85f776dd99
    name: cattle-cluster-agent-85f776dd99
    namespace: cattle-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: cattle-cluster-agent
      uid: 097c0e51-107e-4f1f-a378-6e2e99ecff42
    resourceVersion: "42909"
    uid: 2b8299a8-89e0-4be5-93a3-a20bb4952a30
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: cattle-cluster-agent
        pod-template-hash: 85f776dd99
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: cattle-cluster-agent
          pod-template-hash: 85f776dd99
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/controlplane
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/control-plane
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/master
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: cattle.io/cluster-agent
                  operator: In
                  values:
                  - "true"
              weight: 1
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: beta.kubernetes.io/os
                  operator: NotIn
                  values:
                  - windows
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: app
                    operator: In
                    values:
                    - cattle-cluster-agent
                topologyKey: kubernetes.io/hostname
              weight: 100
        containers:
        - env:
          - name: CATTLE_IS_RKE
            value: "false"
          - name: CATTLE_SERVER
            value: https://44.220.0.65.sslip.io:31403
          - name: CATTLE_CA_CHECKSUM
            value: 3338fce4f2e16671ae970ccb2edb41e59f7c7d5020a76994f60b32ef81acfdda
          - name: CATTLE_CLUSTER
            value: "true"
          - name: CATTLE_K8S_MANAGED
            value: "true"
          - name: CATTLE_CLUSTER_REGISTRY
          - name: CATTLE_SERVER_VERSION
            value: v2.10.2
          - name: CATTLE_INSTALL_UUID
            value: 4d5708cf-c9b5-471e-a07a-95da83c2e32f
          - name: CATTLE_INGRESS_IP_DOMAIN
            value: sslip.io
          - name: STRICT_VERIFY
            value: "false"
          image: rancher/rancher-agent:v2.10.2
          imagePullPolicy: IfNotPresent
          name: cluster-register
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /cattle-credentials
            name: cattle-credentials
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: cattle
        serviceAccountName: cattle
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/controlplane
          value: "true"
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - name: cattle-credentials
          secret:
            defaultMode: 320
            secretName: cattle-credentials-cc48e3e
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: rancher-webhook
      meta.helm.sh/release-namespace: cattle-system
    creationTimestamp: "2025-02-05T14:26:51Z"
    generation: 1
    labels:
      app: rancher-webhook
      pod-template-hash: 586f888bb
    name: rancher-webhook-586f888bb
    namespace: cattle-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: rancher-webhook
      uid: 52e5e943-424d-4926-b1cb-3f7f8ebdd610
    resourceVersion: "128229"
    uid: b057887b-5864-4da1-9e46-ab0034267843
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: rancher-webhook
        pod-template-hash: 586f888bb
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: rancher-webhook
          pod-template-hash: 586f888bb
      spec:
        containers:
        - env:
          - name: STAMP
          - name: ENABLE_MCM
            value: "false"
          - name: CATTLE_PORT
            value: "9443"
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: rancher/rancher-webhook:v0.6.3
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: https
              scheme: HTTPS
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          name: rancher-webhook
          ports:
          - containerPort: 9443
            name: https
            protocol: TCP
          resources: {}
          startupProbe:
            failureThreshold: 60
            httpGet:
              path: /healthz
              port: https
              scheme: HTTPS
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: rancher-webhook
        serviceAccountName: rancher-webhook
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: cattle.io/os
          operator: Equal
          value: linux
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: system-upgrade-controller
      meta.helm.sh/release-namespace: cattle-system
    creationTimestamp: "2025-02-05T14:25:40Z"
    generation: 1
    labels:
      pod-template-hash: 5fb67f585d
      upgrade.cattle.io/controller: system-upgrade-controller
    name: system-upgrade-controller-5fb67f585d
    namespace: cattle-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: system-upgrade-controller
      uid: 33eedbe4-b0db-477a-b2cb-3fda3315857c
    resourceVersion: "115767"
    uid: df948055-3e53-4ec7-a3cd-baefb413b5c1
  spec:
    replicas: 1
    selector:
      matchLabels:
        pod-template-hash: 5fb67f585d
        upgrade.cattle.io/controller: system-upgrade-controller
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: 5fb67f585d
          upgrade.cattle.io/controller: system-upgrade-controller
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/control-plane
                  operator: In
                  values:
                  - "true"
              weight: 100
            - preference:
                matchExpressions:
                - key: node-role.kubernetes.io/master
                  operator: In
                  values:
                  - "true"
              weight: 100
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: kubernetes.io/os
                  operator: NotIn
                  values:
                  - windows
        containers:
        - env:
          - name: SYSTEM_UPGRADE_CONTROLLER_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['upgrade.cattle.io/controller']
          - name: SYSTEM_UPGRADE_CONTROLLER_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          envFrom:
          - configMapRef:
              name: system-upgrade-controller-config
          image: rancher/system-upgrade-controller:v0.14.2
          imagePullPolicy: IfNotPresent
          name: system-upgrade-controller
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            runAsGroup: 65534
            runAsNonRoot: true
            runAsUser: 65534
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/ssl
            name: etc-ssl
            readOnly: true
          - mountPath: /etc/pki
            name: etc-pki
            readOnly: true
          - mountPath: /etc/ca-certificates
            name: etc-ca-certificates
            readOnly: true
          - mountPath: /tmp
            name: tmp
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: system-upgrade-controller
        serviceAccountName: system-upgrade-controller
        terminationGracePeriodSeconds: 30
        tolerations:
        - operator: Exists
        volumes:
        - hostPath:
            path: /etc/ssl
            type: DirectoryOrCreate
          name: etc-ssl
        - hostPath:
            path: /etc/pki
            type: DirectoryOrCreate
          name: etc-pki
        - hostPath:
            path: /etc/ca-certificates
            type: DirectoryOrCreate
          name: etc-ca-certificates
        - emptyDir: {}
          name: tmp
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "10"
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/6xVQW/bOBP9Kx/mLMVW0jaugO/QjbPboq3XqJNeiqCgqZHFNcXhkiMnRqD/vhhJduw2TdrFniyTb4ZvHucN70F58xlDNOQgB+V9HG0ySGBtXAE5TNFb2tboGBKokVWhWEF+D8o5YsWGXJS/tPwLNUfkk2DoRCtmiyeGRkaSQPLDfbp1GNLVZg05rM/iwc4mS/733rji/2+KgtyzKZyqEXLQFLBw8afg0SstMetmiWncRsYa2gSsWqLtilpPYqq830H6vPIZHDJGyTYce0EBp7PFE8dWKlaQw1Lj6eTs9PVkkmXnL87U+GzySi1fZuPytHx1juX5i9MXY/3yXIh8V9ITpKNHLZQDbozc5VsTmcL2g6kNQz5OIKJFzRQEVCvW1YenymwlJQfFuNp2acla41bXvlCMfYq7a6c2yli1tAh51ibAWy/MPh1hZR1rb3dxBy30pNDtQVGaHCvjMETIv9yDCiv5gFSTKyGBEbIeDSqN5CZKYxFuEjC1WgmjoJyuMIxqE4LA0gG8+82zk+z0ZAxDxLyxdk7W6C3k8K6cEc8Dxt4C1mzQYYzzQMuuoFIZ2wS8qgLGimwB+VkCFbP/A1n2vWK591GFynIFCXgKDPlkPJFL0RV2d/z26mouUhln2Cg7Rau2C9Tkigj5q3ECHoOhYr+USXCjNcZ4cHKWAJsaqeEH4GN9JBR6KffKzjtWL8/26AEZiEmThRyup8LwmZCUtT8Ou7p4NOx1dhBYIwej4yOBNwkEVIX5V5JL5PZB8WyS/azi3wt++gt6B4zUBI1da1txYOxbv6YgLZWdjz8a6IB/Nxj7Xe0b2RqP627QDtAeKVZA3QTD2wtyjHddmcpaup0HszEWV3gZtbLdPIa8VDZiAlp5tTTWsOmpqKIQ28wur77+9m42/bq4/PT53cWlOKUI5GVPWQs3bS/6n85uPxHx78biMGhyDg22CWzINjV+pMYNfVTL53zQ/cCOcNB9rjSrtI+EhxN2OX+cY6SbyFQfpOr+p89kvJHmKVzcO3mKpWqsmNhRgYuDeXg80ilCDta45k7uyAdDnfBWxTjrCfRqpNo2kTGkOhg2WlmQawobo/GN1lLM7FvjMVkMu0fzyz2sUYhdDPHdQxe7EhIgL0jhB5d3RppENMKyRM2Qw4wWusKisVJ5n0aqSgNZPDmuR5wXyKbeKof/aeZaSf2Pp7yRaj1ZWm0XXq7mgpy8KGbXMt30X/zyq1Sru8Uab3vzDQe871gec6soctcvCdxW6K5dVGxiafrnCqY0I94XKmz7PtqPxdKsPiovRAxjfXRduxcm2U2a/YoI2YNmVOBbEiX2qIclOe6bodz+wCjD6HxgcxyX7r1BXtpK2b1HnzJLe9O2bftPAAAA//8kyNqv/AkAAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: k3s.cattle.io/v1, Kind=Addon
      objectset.rio.cattle.io/owner-name: coredns
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2025-02-05T14:24:18Z"
    generation: 1
    labels:
      k8s-app: kube-dns
      pod-template-hash: 8544b8dd7b
    name: coredns-8544b8dd7b
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: coredns
      uid: 1c1b9020-d7ff-4877-bce4-3243352e62bf
    resourceVersion: "115776"
    uid: 470209f8-cd7f-4c81-83fe-eadad04c1455
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: kube-dns
        pod-template-hash: 8544b8dd7b
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-02-05T14:24:18Z"
        creationTimestamp: null
        labels:
          k8s-app: kube-dns
          pod-template-hash: 8544b8dd7b
      spec:
        containers:
        - args:
          - -conf
          - /etc/coredns/Corefile
          image: rancher/mirrored-coredns-coredns:1.12.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /health
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: coredns
          ports:
          - containerPort: 53
            name: dns
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 9153
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: 8181
              scheme: HTTP
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - all
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/coredns
            name: config-volume
            readOnly: true
          - mountPath: /etc/coredns/custom
            name: custom-config-volume
            readOnly: true
        dnsPolicy: Default
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: coredns
        serviceAccountName: coredns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        topologySpreadConstraints:
        - labelSelector:
            matchLabels:
              k8s-app: kube-dns
          maxSkew: 1
          topologyKey: kubernetes.io/hostname
          whenUnsatisfiable: DoNotSchedule
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: Corefile
              path: Corefile
            - key: NodeHosts
              path: NodeHosts
            name: coredns
          name: config-volume
        - configMap:
            defaultMode: 420
            name: coredns-custom
            optional: true
          name: custom-config-volume
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/6xUXWvrRhD9K2WeJdmuE2MEfTBJSksTxySkL8GU8Wpkb7zaXXbHaoTRf7+MJeeDGyf3wn3SfsycPTPnjPaAXv9LIWpnIQf0Pg7qESSw1baAHC7JG9dUZBkSqIixQEbI94DWOkbWzkbZutUTKY7EWdAuU8hsKNNuoAUEkpP37n9LIV3XW8hhO45vbupR8ts/2hZ/zIrC2S8hLFYEORin0KSRXcA1/VBS9Kgkc7tbURqbyFRBm4DBFZlPS9tg3EAOo+m4HJ+ryXlZrtR4ODmbDMfl2bgcnU+HxVRNpvh7gaviTEDfkfTIm9QHV2tpPgXo7k/wiZ6UsAnUxf+lpcjmWleaIR8mEMmQYhckqEJWm+uXCtD706+2As4BmdbN4QFnjLbrB18gUwf2/GCxRm1wZQjyUZsAN1443r2LlXOqvDnmvXGL+QkufaHKWUZtKUTIH2VbVSiWfDzdvsgYxKdpqpwt9RoSGBCrQbfrP9lTdBaWCZCtD8i9KIvby//ms5ur+8Xs4goSqNHs6M/gKiFTajLFHZUv6wWyiH+sMXtVrm3bZQK6Ev/lENCqDYXBx5zzepgNs/EQ+oTFzpiFM1o1kMPf5dzxIlDshu8r79TO7Cq6cTvLXccqWfY837bhFas7SLtMaJdC3AftgubmwmCM8y6uc2FqXUGpCpq1QiPtplBrRTOl5KX5Z/zSPjbFLhgSYGcoHH8gj3vYkhR90cMfhj7eWtPIEHuJFGvD1bOOHKFN9kBlSYohh7m7VxsqdkYGvoM5UA3OUCZjFCwxRZlZMVVwJvUGLf1S5AojH3T4AHJ5VOdoZWn7DXpx0/ey9t5tT8vUtu23AAAA///s6eu+uAUAAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: k3s.cattle.io/v1, Kind=Addon
      objectset.rio.cattle.io/owner-name: local-storage
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2025-02-02T14:26:20Z"
    generation: 1
    labels:
      app: local-path-provisioner
      pod-template-hash: 5cf85fd84d
    name: local-path-provisioner-5cf85fd84d
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: local-path-provisioner
      uid: fc801ef2-1c56-48f8-918d-8a6055db4094
    resourceVersion: "115736"
    uid: 238ad84a-5d83-4480-852b-7877efd458d1
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: local-path-provisioner
        pod-template-hash: 5cf85fd84d
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: local-path-provisioner
          pod-template-hash: 5cf85fd84d
      spec:
        containers:
        - command:
          - local-path-provisioner
          - start
          - --config
          - /etc/config/config.json
          env:
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: rancher/local-path-provisioner:v0.0.30
          imagePullPolicy: IfNotPresent
          name: local-path-provisioner
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config/
            name: config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: local-path-provisioner-service-account
        serviceAccountName: local-path-provisioner-service-account
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: local-path-config
          name: config-volume
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/6xV4W8auRP9V36az7vJLoHQrsQHRPiV6tIUFXqnUxUh4x3Ah9f2eWZpuIj//TS7SUovpelV9wUt9vPzmzfjmXtQwfyKkYx3UIAKgc53OSSwNa6EAq4wWL+v0DEkUCGrUrGC4h6Uc54VG+9I/vrlH6iZkM+i8WdaMVs8M/7cCAkkJ/f9Z4cxXe+2UMD2go52dnnyv1+MKwfDsvTuRQqnKoRCJEajKSWMO4xpeSz/ZQIKSgvLtl5iSntirOCQgFVLtE2Y21eUqhCeXfQd9o2iDRSAeYadbg/zC+xeqn6np1+XZVl2V69x2bl4vcq7/X6/uyrlvm/GAu36CYkUUIvAiDsjuZwYYh/316YyDEWWAKFFzT4KqFKsN9cvB3UQYo6Kcb1vyL21xq0/hlIxtkR3H53aKWPV0iIU+SEB3gfR9+ErrKxjFezjuaNC+gFzT1pyFLj2jpVxGAmKT/eg4lo+IE01Rk5LEwfnXAVIIE0JdR0xDT7yIM86vaxZFUMtchoirjBGLFNVlhGJUomIBm8dY3TKvp0m47unz4knbrQdU9SEqfMlpsSKa2puagCt/DQieVvL2xnkPWp22FKqTdhgTKk2jDSYX88W49HVZCy/s+Hit7fzyWI4ni06vcvFm9G7xWwyvHjVTb7gPvwQ6h9seefVI67TuzzFdhJ1xDaaDEeTYSdbTN9f/55fZL1vkT0DwW0CplJryW5UTm8wnlcmRi8Z+DrdxS476591IAFrduiQaBr9simolTK2jjjfRKSNtyUUFwlsmMMbZNkPiuURnsvBvyCBJiNFgxD/SW+wqa/JfD6dSVkZZ9goe4VW7WeovSsJisssgYDR+PJpKZenVWuNREeX5wmwqdDX/AX4nXctatqyfariaSOwqc6nc49qQ/TstbdQwHw0hcNtAhFVaX7KETm5/3lLnjvS+ReGyEOoo0ZqW9efNRI33zrUUECeZVUzdiof91BAP3tn2qYkL9jwfuQd410Tj7LWf55GszMW1zgmrWwznaBYKUvYWvTe2f0H7/n/xuJD7yw41rJbuyHdeCe7X619JIySiCw7JLDztq7wna/dQ74q+Zw+WNn2l4dkcRWk68DhVvITovGNYKuIblpEK6BtFDoaNlpZMR7jzmgcai3cNydKhr3F+Dh+P93DFsWg0QNNMzJJopXBFAQpnR/Gd0YMPiT3gKsVakn4jZ/pDZa1lR7W0jSSord4Jh0tOmQkGWVSndHbNFjl8D9lrhRxO0WfU94++t5GilXg/ZWRQXb4ltuHw+HvAAAA//9PFN5y1QgAAA
      objectset.rio.cattle.io/id: ""
      objectset.rio.cattle.io/owner-gvk: k3s.cattle.io/v1, Kind=Addon
      objectset.rio.cattle.io/owner-name: metrics-server-deployment
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2025-02-02T14:26:20Z"
    generation: 1
    labels:
      k8s-app: metrics-server
      pod-template-hash: 5985cbc9d7
    name: metrics-server-5985cbc9d7
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: metrics-server
      uid: ef8c123e-bb01-46a8-aa98-61da6c93a682
    resourceVersion: "128239"
    uid: 59c52ce2-85ec-448d-bfb7-b62f2f7fd964
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: metrics-server
        pod-template-hash: 5985cbc9d7
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: metrics-server
          pod-template-hash: 5985cbc9d7
        name: metrics-server
      spec:
        containers:
        - args:
          - --cert-dir=/tmp
          - --secure-port=10250
          - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
          - --kubelet-use-node-status-port
          - --metric-resolution=15s
          - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305
          image: rancher/mirrored-metrics-server:v0.7.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /livez
              port: https
              scheme: HTTPS
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: metrics-server
          ports:
          - containerPort: 10250
            name: https
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: https
              scheme: HTTPS
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp
            name: tmp-dir
        dnsPolicy: ClusterFirst
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metrics-server
        serviceAccountName: metrics-server
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - emptyDir: {}
          name: tmp-dir
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      field.cattle.io/publicEndpoints: '[{"addresses":["172.31.18.33","172.31.23.7"],"port":80,"protocol":"TCP","serviceName":"kube-system:traefik","allNodes":false},{"addresses":["172.31.18.33","172.31.23.7"],"port":443,"protocol":"TCP","serviceName":"kube-system:traefik","allNodes":false}]'
      meta.helm.sh/release-name: traefik
      meta.helm.sh/release-namespace: kube-system
    creationTimestamp: "2025-02-02T14:26:30Z"
    generation: 1
    labels:
      app.kubernetes.io/instance: traefik-kube-system
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: traefik
      helm.sh/chart: traefik-27.0.201_up27.0.2
      pod-template-hash: 5d45fc8cc9
    name: traefik-5d45fc8cc9
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: traefik
      uid: d9dd6749-759a-41dd-93d1-b43c038801e2
    resourceVersion: "115825"
    uid: 5eb73b9d-7a72-4616-b644-44664ab1c5c7
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/instance: traefik-kube-system
        app.kubernetes.io/name: traefik
        pod-template-hash: 5d45fc8cc9
    template:
      metadata:
        annotations:
          prometheus.io/path: /metrics
          prometheus.io/port: "9100"
          prometheus.io/scrape: "true"
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: traefik-kube-system
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: traefik
          helm.sh/chart: traefik-27.0.201_up27.0.2
          pod-template-hash: 5d45fc8cc9
      spec:
        containers:
        - args:
          - --global.checknewversion
          - --global.sendanonymoususage
          - --entrypoints.metrics.address=:9100/tcp
          - --entrypoints.traefik.address=:9000/tcp
          - --entrypoints.web.address=:8000/tcp
          - --entrypoints.websecure.address=:8443/tcp
          - --api.dashboard=true
          - --ping=true
          - --metrics.prometheus=true
          - --metrics.prometheus.entrypoint=metrics
          - --providers.kubernetescrd
          - --providers.kubernetesingress
          - --providers.kubernetesingress.ingressendpoint.publishedservice=kube-system/traefik
          - --entrypoints.websecure.http.tls=true
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: rancher/mirrored-library-traefik:2.11.18
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /ping
              port: 9000
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          name: traefik
          ports:
          - containerPort: 9100
            name: metrics
            protocol: TCP
          - containerPort: 9000
            name: traefik
            protocol: TCP
          - containerPort: 8000
            name: web
            protocol: TCP
          - containerPort: 8443
            name: websecure
            protocol: TCP
          readinessProbe:
            failureThreshold: 1
            httpGet:
              path: /ping
              port: 9000
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /data
            name: data
          - mountPath: /tmp
            name: tmp
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroupChangePolicy: OnRootMismatch
          runAsGroup: 65532
          runAsNonRoot: true
          runAsUser: 65532
        serviceAccount: traefik
        serviceAccountName: traefik
        terminationGracePeriodSeconds: 60
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - emptyDir: {}
          name: data
        - emptyDir: {}
          name: tmp
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "2"
      deployment.kubernetes.io/max-replicas: "3"
      deployment.kubernetes.io/revision: "1"
      field.cattle.io/publicEndpoints: '[{"port":30088,"protocol":"TCP","serviceName":"nginx:nginx-service","allNodes":true}]'
    creationTimestamp: "2025-02-11T12:36:08Z"
    generation: 1
    labels:
      app: nginx
      pod-template-hash: 54b9c68f67
    name: nginx-deployment-54b9c68f67
    namespace: nginx
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: nginx-deployment
      uid: 0d3eff49-f2e1-4c9b-ae7c-b2ed21d3564e
    resourceVersion: "128091"
    uid: e6aa2e43-8555-479e-900f-6779d29973fc
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: nginx
        pod-template-hash: 54b9c68f67
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: nginx
          pod-template-hash: 54b9c68f67
      spec:
        containers:
        - image: nginx:latest
          imagePullPolicy: Always
          name: nginx
          ports:
          - containerPort: 80
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 2
    fullyLabeledReplicas: 2
    observedGeneration: 1
    readyReplicas: 2
    replicas: 2
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2025-02-06T15:27:39Z"
    generation: 2
    labels:
      component: velero
      deploy: velero
      pod-template-hash: 57fdbd48db
    name: velero-57fdbd48db
    namespace: velero
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: velero
      uid: 27f1d208-f1e3-4f0b-a641-d4648812cf24
    resourceVersion: "66377"
    uid: d0401da5-d622-4a54-9535-d367146512d3
  spec:
    replicas: 0
    selector:
      matchLabels:
        deploy: velero
        pod-template-hash: 57fdbd48db
    template:
      metadata:
        annotations:
          prometheus.io/path: /metrics
          prometheus.io/port: "8085"
          prometheus.io/scrape: "true"
        creationTimestamp: null
        labels:
          component: velero
          deploy: velero
          pod-template-hash: 57fdbd48db
      spec:
        containers:
        - args:
          - server
          - --features=
          - --uploader-type=kopia
          command:
          - /velero
          env:
          - name: VELERO_SCRATCH_DIR
            value: /scratch
          - name: VELERO_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: LD_LIBRARY_PATH
            value: /plugins
          image: velero/velero:v1.15.2
          imagePullPolicy: IfNotPresent
          name: velero
          ports:
          - containerPort: 8085
            name: metrics
            protocol: TCP
          resources:
            limits:
              cpu: "1"
              memory: 512Mi
            requests:
              cpu: 500m
              memory: 128Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /plugins
            name: plugins
          - mountPath: /scratch
            name: scratch
        dnsPolicy: ClusterFirst
        initContainers:
        - image: velero/velero-plugin-for-aws:v1.10.0
          imagePullPolicy: IfNotPresent
          name: velero-velero-plugin-for-aws
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /target
            name: plugins
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: velero
        serviceAccountName: velero
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: plugins
        - emptyDir: {}
          name: scratch
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "3"
    creationTimestamp: "2025-02-09T06:08:17Z"
    generation: 1
    labels:
      component: velero
      deploy: velero
      pod-template-hash: 5844478ff5
    name: velero-5844478ff5
    namespace: velero
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: velero
      uid: 27f1d208-f1e3-4f0b-a641-d4648812cf24
    resourceVersion: "128170"
    uid: aa4b2103-7f20-4a67-bb5e-34e9d6f9768d
  spec:
    replicas: 1
    selector:
      matchLabels:
        deploy: velero
        pod-template-hash: 5844478ff5
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-02-09T06:08:17Z"
          prometheus.io/path: /metrics
          prometheus.io/port: "8085"
          prometheus.io/scrape: "true"
        creationTimestamp: null
        labels:
          component: velero
          deploy: velero
          pod-template-hash: 5844478ff5
      spec:
        containers:
        - args:
          - server
          - --features=
          - --uploader-type=kopia
          command:
          - /velero
          env:
          - name: VELERO_SCRATCH_DIR
            value: /scratch
          - name: VELERO_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: LD_LIBRARY_PATH
            value: /plugins
          image: velero/velero:v1.15.2
          imagePullPolicy: IfNotPresent
          name: velero
          ports:
          - containerPort: 8085
            name: metrics
            protocol: TCP
          resources:
            limits:
              cpu: "1"
              memory: 512Mi
            requests:
              cpu: 500m
              memory: 128Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /plugins
            name: plugins
          - mountPath: /scratch
            name: scratch
        dnsPolicy: Default
        initContainers:
        - image: velero/velero-plugin-for-aws:v1.10.0
          imagePullPolicy: IfNotPresent
          name: velero-velero-plugin-for-aws
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /target
            name: plugins
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: velero
        serviceAccountName: velero
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: plugins
        - emptyDir: {}
          name: scratch
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "2"
    creationTimestamp: "2025-02-09T06:08:01Z"
    generation: 2
    labels:
      component: velero
      deploy: velero
      pod-template-hash: 85789564f5
    name: velero-85789564f5
    namespace: velero
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: velero
      uid: 27f1d208-f1e3-4f0b-a641-d4648812cf24
    resourceVersion: "66425"
    uid: 0b66f189-2c9b-49bf-a1cd-71052dd1c32e
  spec:
    replicas: 0
    selector:
      matchLabels:
        deploy: velero
        pod-template-hash: 85789564f5
    template:
      metadata:
        annotations:
          prometheus.io/path: /metrics
          prometheus.io/port: "8085"
          prometheus.io/scrape: "true"
        creationTimestamp: null
        labels:
          component: velero
          deploy: velero
          pod-template-hash: 85789564f5
      spec:
        containers:
        - args:
          - server
          - --features=
          - --uploader-type=kopia
          command:
          - /velero
          env:
          - name: VELERO_SCRATCH_DIR
            value: /scratch
          - name: VELERO_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: LD_LIBRARY_PATH
            value: /plugins
          image: velero/velero:v1.15.2
          imagePullPolicy: IfNotPresent
          name: velero
          ports:
          - containerPort: 8085
            name: metrics
            protocol: TCP
          resources:
            limits:
              cpu: "1"
              memory: 512Mi
            requests:
              cpu: 500m
              memory: 128Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /plugins
            name: plugins
          - mountPath: /scratch
            name: scratch
        dnsPolicy: Default
        initContainers:
        - image: velero/velero-plugin-for-aws:v1.10.0
          imagePullPolicy: IfNotPresent
          name: velero-velero-plugin-for-aws
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /target
            name: plugins
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: velero
        serviceAccountName: velero
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: plugins
        - emptyDir: {}
          name: scratch
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    annotations:
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/8xVbW/bNhD+L/ysOHa8tIm+ebbSGXVsw043DIURnKiTzZUiNfLoxgv034eT5Jd0adABDZBvInXvz3N8HkWBBBkQiPhRgDGWgJQ1no82/QsleaSOU7YjgUhjR9lzlYlY5BqRzmCNhs5Sa8mTg1JUkZAO6xB3qkBPUJQiNkHrSGhIUb8YeAN+w6H719dZN+33unmapxdXeP3u3ft+7yLP5Hvo968vf8GL9EpecTYDBT6tRjSXvgTJf5roZ42B33nCgv18iZJL8ahRknX8XQDJzeRQJZTlN5ErdkS3VRKnz+UlLEoNhHWwk7n+wEi+k6ytEvJcGUU7/jY2w8HJuXSYo3OYjYJTZr2UG8yCVmY9Xht7uE4eUAauQcSf9z5oJB76Th5Kh9432H9+FF9wty/oBKF9p7ZEB/XYxNiISGxBB2RHQS6gWFWrKhJfUa03JOJeteJmpDUEyqBrEkhbFGAy9qmzNKFXkUCzrQ1aaH/9NB1NklEyn8z+vE2md/eLZDibDseTZHH/x2zxMVks9wWIWFx2RRUdfEeL8c3/cpgObpPlfDBM9hY3zhY8o1yhzhaYH77nQMzVPcydI+eq6iTg4AOXvBzO5omoVpFQBaz53oGRG3TnJ4jH226n1+v0RWs1D1rPrVaSgRjnU0tzh/7I8P/Qz6G3wUnG4bFmqgxO0W5oDeED1TzS2n6dO7VVGteYeAkaGlLkoD1GQkIJqdKKVB1FZM6WjNBgMhEMabn3zQ4uDiGbGb1bWEs3SmO7YzEToYrE1upQ4K0NhhrcC/5sp3fe+RJSPPZTn5g736NHJKQOntB5Agr+Gbr8dASHvyXDj+Pp/Xh6lyx+H0xOuNO7LLr+dWE9e9rvmwS5HoBRNPyRBedYa8UtvR54rwrIofw3iwUrxPJE13irnEFCz0+49SIWWpnwIJ6v2QUz8B+cDaWIe91uN2puptZwxiZPe/fJo2uMjso4kJI3/HmBtJp14yAymOcoiYG3rW7xY9BID3fRkdqGrHR2qzJ0naeNBMOkU6DVP5g91aTk7wD6ZFFrUeKdfinhUeWsfzlcO73V/nVrmylK2o2Ua8jwzYtWRSKUGRAuyQHhmqW7Vvhmr5kqW1AaUo0LLLWS4EXMoz8equrfAAAA//8mGISYrgkAAA
      objectset.rio.cattle.io/id: fleet-agent-bootstrap
    creationTimestamp: "2025-02-05T14:24:41Z"
    generation: 1
    labels:
      objectset.rio.cattle.io/hash: f399d0b310fbfb28e9667312fdc7a33954e2b8c8
    name: fleet-agent
    namespace: cattle-fleet-system
    resourceVersion: "56408"
    uid: 72baacf5-a8af-4aac-a2ca-b3aa42483fcb
  spec:
    persistentVolumeClaimRetentionPolicy:
      whenDeleted: Retain
      whenScaled: Retain
    podManagementPolicy: OrderedReady
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: fleet-agent
    serviceName: fleet-agent
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: fleet-agent
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: fleet.cattle.io/agent
                  operator: In
                  values:
                  - "true"
              weight: 1
        containers:
        - command:
          - fleetagent
          env:
          - name: BUNDLEDEPLOYMENT_RECONCILER_WORKERS
            value: "50"
          - name: DRIFT_RECONCILER_WORKERS
            value: "50"
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: AGENT_SCOPE
          image: rancher/fleet-agent:v0.11.3
          imagePullPolicy: IfNotPresent
          name: fleet-agent
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /.kube
            name: kube
        - command:
          - fleetagent
          - clusterstatus
          env:
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: CHECKIN_INTERVAL
            value: 15m0s
          image: rancher/fleet-agent:v0.11.3
          imagePullPolicy: IfNotPresent
          name: fleet-agent-clusterstatus
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        initContainers:
        - command:
          - fleetagent
          - register
          env:
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: rancher/fleet-agent:v0.11.3
          imagePullPolicy: IfNotPresent
          name: fleet-agent-register
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          runAsGroup: 1000
          runAsNonRoot: true
          runAsUser: 1000
        serviceAccount: fleet-agent
        serviceAccountName: fleet-agent
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node.cloudprovider.kubernetes.io/uninitialized
          operator: Equal
          value: "true"
        - effect: NoSchedule
          key: cattle.io/os
          operator: Equal
          value: linux
        volumes:
        - emptyDir: {}
          name: kube
    updateStrategy:
      rollingUpdate:
        partition: 0
      type: RollingUpdate
  status:
    availableReplicas: 0
    collisionCount: 0
    currentReplicas: 1
    currentRevision: fleet-agent-6f4bc75f47
    observedGeneration: 1
    replicas: 1
    updateRevision: fleet-agent-6f4bc75f47
    updatedReplicas: 1
- apiVersion: batch/v1
  kind: Job
  metadata:
    annotations:
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/6xW34/aOBD+V06W+nRJSALLj0h9yEL24MpCFGh1p9MKGTMBH44d2Q4tWvG/n+yk3WzZbrfSvdlm5svMfN/M8IhwST+BVFRwFKEt1uTQOQXIQUfKdyhCf4otclABGu+wxih6RJhzobGmgitzFdt/gWgF2pNUeARrzcCjokON9wFY4RLBtRSMgXTJAUvtSthTpaXFQM4PEcRnDtLdn44NUOunU+D89oHy3fspsGJsQH+Kw3EBKEJaYsjp8U3mqsTE+ByrLbjqrDQU6OIgIsGGvqYFKI2LEkW8YsxBDG+B2aKYcG2uyvsucvv6pjgOWB1QhIifjwaABzi8ge4OyCAY3QzIAHfDXoC7w7wLNzmGm9xE1uRoq0650pgx9+lDP0rJQTblDHKQwAkoFP3znS6uyo8ctGWCHJfGcwIMLJdRjpkCBz0x/u2pkVObrytGKquZUdjtDcJ+3/V7253bw8PAHeY3Xbff90m3N8pJ3h+gy8PFQaoEYqq9xeQo8nxOC6pRFPi+7yANRcmwBvP7K+p9hSjBc7qf1iSspnF403+f3PVvhsFwNB4G/WHQC/xxcDtIwuH4dnTn+10/GPij7vB2NJoE48kgGY+Snn87DMPB/y6bSyt9U21MOciGOLk3B9QIADnIdRVoV2lJ+R45aM/EFjOvZn8COa6YzuqWPL9HDw4CfrJIDUGL+D5BDjphVrX5ujjfLD4l2Wq2XLSfsiRdtu/TZH6/mWSzT0nWwlJAJOi23XgaZ+uN+eQqjcft7z7vwucOLbOD1qWKOp13jx8+3ibZIlknq02czi7vOsoQT+paqk6ThxsOPN8L/eD3qjTHq6BfSG4dZ38kvxRl/HE93aTxarUZZ8kkWaxn8XzVcrNd0naYLVbJ+GOWbFYfZulmPV+ZOGZ3f7/mk87j2WIzXa/T16wWy02aLf9qI3nqRByPsEppkB4TBDMn8L1e6Pme3wn69tJtLm2su3g2N0Gmy/ls3EaU8FV+lwcH0QLv7Svm5ACyc2S0LEG6RuTRyfdGXtfdVpTtQj/sBb4/RI1PWjGWCkbJ2ZQkXwidSlDAW+PDYCAHSVCiknZ4PZreAFJJqs9jwTV80bbzGROfU0lPlMEeEkUww8+nFi7xljKqqUVBOylK00jxfI7MuJGAd0vOzpkQ+o4yaFiOtKzg4qCTYFUB96Lium7EwhxTrM0A6RxEAc/y7nhN5E0e7d9siX/mTjA5wLV//fwmADvhXkCo368gdFG2pnZRXlt8j2jVoF6we74BzAAznF4ejFi42MEKGBAtpKHBdJTkoEHZ7axQhBjl1RdkKVEaS/1NIkt+hymrpKnLCxKQFY/VQnDDYM2bNSOiKFMpcsrsutDn0k6wimtaQDMg64kL8kQJxISYbBatbfu0xGoZ1AqAotTnCZX1EtrRqkARuodCyHNrXV8x/2tuT4T/ot8TzW9z/Er5c3Kdr0M8emxOTV3q/3q1ldvaW3Zh5XR/j0vjw9vWjRKezF/SiGVCY13ZXr/8FwAA///n0uh/wwoAAA
      objectset.rio.cattle.io/id: helm-controller-chart-registration
      objectset.rio.cattle.io/owner-gvk: helm.cattle.io/v1, Kind=HelmChart
      objectset.rio.cattle.io/owner-name: traefik
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2025-02-02T14:26:18Z"
    generation: 1
    labels:
      helmcharts.helm.cattle.io/chart: traefik
      objectset.rio.cattle.io/hash: c0f97ea7a25e3dec71957c7a3241a38f3e5fae5f
    name: helm-install-traefik
    namespace: kube-system
    ownerReferences:
    - apiVersion: helm.cattle.io/v1
      blockOwnerDeletion: false
      controller: false
      kind: HelmChart
      name: traefik
      uid: 92347266-04bd-4a81-8f53-660c349fcf67
    resourceVersion: "658"
    uid: 506b1ba9-f9f4-4264-9980-b16dba6e8399
  spec:
    backoffLimit: 1000
    completionMode: NonIndexed
    completions: 1
    manualSelector: false
    parallelism: 1
    podReplacementPolicy: TerminatingOrFailed
    selector:
      matchLabels:
        batch.kubernetes.io/controller-uid: 506b1ba9-f9f4-4264-9980-b16dba6e8399
    suspend: false
    template:
      metadata:
        annotations:
          helmcharts.helm.cattle.io/configHash: SHA256=EF658189C81681410C1B7E28CB9F0030170938B99D1CD7EC9E40B82278BB67A8
        creationTimestamp: null
        labels:
          batch.kubernetes.io/controller-uid: 506b1ba9-f9f4-4264-9980-b16dba6e8399
          batch.kubernetes.io/job-name: helm-install-traefik
          controller-uid: 506b1ba9-f9f4-4264-9980-b16dba6e8399
          helmcharts.helm.cattle.io/chart: traefik
          job-name: helm-install-traefik
      spec:
        containers:
        - args:
          - install
          - --set-string
          - global.systemDefaultRegistry=
          env:
          - name: NAME
            value: traefik
          - name: VERSION
          - name: REPO
          - name: HELM_DRIVER
            value: secret
          - name: CHART_NAMESPACE
            value: kube-system
          - name: CHART
            value: https://%{KUBERNETES_API}%/static/charts/traefik-27.0.201+up27.0.2.tgz
          - name: HELM_VERSION
          - name: TARGET_NAMESPACE
            value: kube-system
          - name: AUTH_PASS_CREDENTIALS
            value: "false"
          - name: INSECURE_SKIP_TLS_VERIFY
            value: "false"
          - name: PLAIN_HTTP
            value: "false"
          - name: NO_PROXY
            value: .svc,.cluster.local,10.42.0.0/16,10.43.0.0/16
          - name: FAILURE_POLICY
            value: reinstall
          image: rancher/klipper-helm:v0.9.3-build20241008
          imagePullPolicy: IfNotPresent
          name: helm
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /home/klipper-helm/.helm
            name: klipper-helm
          - mountPath: /home/klipper-helm/.cache
            name: klipper-cache
          - mountPath: /home/klipper-helm/.config
            name: klipper-config
          - mountPath: /tmp
            name: tmp
          - mountPath: /config
            name: values
          - mountPath: /chart
            name: content
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: OnFailure
        schedulerName: default-scheduler
        securityContext:
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: helm-traefik
        serviceAccountName: helm-traefik
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir:
            medium: Memory
          name: klipper-helm
        - emptyDir:
            medium: Memory
          name: klipper-cache
        - emptyDir:
            medium: Memory
          name: klipper-config
        - emptyDir:
            medium: Memory
          name: tmp
        - name: values
          secret:
            defaultMode: 420
            secretName: chart-values-traefik
        - configMap:
            defaultMode: 420
            name: chart-content-traefik
          name: content
  status:
    completionTime: "2025-02-02T14:26:34Z"
    conditions:
    - lastProbeTime: "2025-02-02T14:26:34Z"
      lastTransitionTime: "2025-02-02T14:26:34Z"
      message: Reached expected number of succeeded pods
      reason: CompletionsReached
      status: "True"
      type: SuccessCriteriaMet
    - lastProbeTime: "2025-02-02T14:26:34Z"
      lastTransitionTime: "2025-02-02T14:26:34Z"
      message: Reached expected number of succeeded pods
      reason: CompletionsReached
      status: "True"
      type: Complete
    ready: 0
    startTime: "2025-02-02T14:26:20Z"
    succeeded: 1
    terminating: 0
    uncountedTerminatedPods: {}
- apiVersion: batch/v1
  kind: Job
  metadata:
    annotations:
      objectset.rio.cattle.io/applied: H4sIAAAAAAAA/7RWUY/aOBD+KydLfbokJCG7bCL1IcuGgysLEdDqTqcVcswEfDh2ZDu0aMV/P9mkbdjdbrcP90ac+b7MzPd5hkeEa/oJpKKCowQVWJNd7xAgB+0p36AE/SkK5KAKNN5gjVHyiDDnQmNNBVfmURT/AtEKtCep8AjWmoFHRY8a9A5Y5RLBtRSMgXTJDkvtSthSpaXlQM4PGcRnDtLdHvYtUefVIXB++0D55v0YWDU0pD/l4bgClCAtMZR07xK5eRNE1ZgY3L4pwFVHpaFCJwcRCTb9Fa1AaVzVKOENYw5iuABmG2NStvUq70n29vTNueyw2qEERTdl2d9ckX4QDIr+ICzJhuArPx7EV2VchgM/xKV/FYcmu7ZW233KlcaMuZcf+1FpDrKlL6AECZyAQsk/TzzyTArkoIIJsp8b5B0wsLomJWYKHPRd/W9HrbW62r2oTmM9hMvNIMBh7A78kLgRBAMXb0jo+kX/hkCBi5siQKeHk4NUDcR0vsBkL8pySiuqURL4vu8gDVXNsAbz/hU3vyKa4CXdjs9iLMdpeHX9Puvf+sMoCuOb0TAYBlGcjm5H0fAmjq9Ht3EYhYM0i4Isuo7i27gfDdMovorj4Hbwv1jo1GmB6TqmHGQroNyaH6g1A3pwEPCDfdV2fpbeZ8hBB8yap0KcnG9Rn7LFcjKfdY8WWT7vPo+z6f36bjH5lC06fAqIBN2NG47TxWptPrvM02H325dX7RLQCdtpXauk13v3+OHjbbaYZatsuU7zyeldTxlFyblJqtepxQ0Hnu+FfvB7Uz9L+oXiVunij+yXskw/rsbrPF0u18NFdpfNVpN0uuzA7BXoAiazZTb8uMjWyw+TfL2aLk0ek9Hfr2HyaTqZrcerVf5a1Gy+zhfzv7pMnjoQxyOsURqkxwTBzAl8Lwo93/N7wbV96LcPXa5ROpmaJPP5dDLsMkr46qnTg4Nohbf2FHOyA9nbM1rXIF3j3uTge7HXd4uGsk3oh1Hg+zeoxeQNY7lglBxNS8qZ0LkEBbwzGwwHcpAEJRppJ9OjMTyQRlJ9HAqu4Yu2V5ox8TmX9EAZbCFTBDN8OZJwjQvKqKaWBW2kqM3tSKdTZOaIBLyZc3ZcCKFHlEGrcqJlAycHHQRrKrgXDdfn21WZnznWZjL0dqKCi7p7Xpt5W0f3nW3xz+AEkx08x5+P30RgR9cLDOfzZxS6qjsjuaqfRzxltG5QL8RdjnczlYympwdjFi42sAQGRAtpZDA3SnLQoOwKVihBjPLmC7KSKI2l/maROR9hyhpp+vKCBWTDUzUT3Ch41s2GEVHVuRQlZXYP6GNtJ1jDNa3gDkrcMH0eoyAPlEBKiKlm1lmnlxvqbIWzC6Cq9fGOyvOG2dCmQgm6h0rIY2cnP1P/12DfRf9F3Hep3wb8KvulwM7XQZ48tr/a3pz/2J2j3CdLyW6jkm7vcW1wvItoHXEJeckvVhWNdWPv/em/AAAA///1kMdOuAoAAA
      objectset.rio.cattle.io/id: helm-controller-chart-registration
      objectset.rio.cattle.io/owner-gvk: helm.cattle.io/v1, Kind=HelmChart
      objectset.rio.cattle.io/owner-name: traefik-crd
      objectset.rio.cattle.io/owner-namespace: kube-system
    creationTimestamp: "2025-02-02T14:26:18Z"
    generation: 1
    labels:
      helmcharts.helm.cattle.io/chart: traefik-crd
      objectset.rio.cattle.io/hash: 48ff3d5c3117b372fcdca509795f9f2702af0592
    name: helm-install-traefik-crd
    namespace: kube-system
    ownerReferences:
    - apiVersion: helm.cattle.io/v1
      blockOwnerDeletion: false
      controller: false
      kind: HelmChart
      name: traefik-crd
      uid: afd71a29-702c-4e17-adc2-0b38cebab8b1
    resourceVersion: "630"
    uid: ec5580de-ae16-46db-82e3-d8432011d841
  spec:
    backoffLimit: 1000
    completionMode: NonIndexed
    completions: 1
    manualSelector: false
    parallelism: 1
    podReplacementPolicy: TerminatingOrFailed
    selector:
      matchLabels:
        batch.kubernetes.io/controller-uid: ec5580de-ae16-46db-82e3-d8432011d841
    suspend: false
    template:
      metadata:
        annotations:
          helmcharts.helm.cattle.io/configHash: SHA256=E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855
        creationTimestamp: null
        labels:
          batch.kubernetes.io/controller-uid: ec5580de-ae16-46db-82e3-d8432011d841
          batch.kubernetes.io/job-name: helm-install-traefik-crd
          controller-uid: ec5580de-ae16-46db-82e3-d8432011d841
          helmcharts.helm.cattle.io/chart: traefik-crd
          job-name: helm-install-traefik-crd
      spec:
        containers:
        - args:
          - install
          env:
          - name: NAME
            value: traefik-crd
          - name: VERSION
          - name: REPO
          - name: HELM_DRIVER
            value: secret
          - name: CHART_NAMESPACE
            value: kube-system
          - name: CHART
            value: https://%{KUBERNETES_API}%/static/charts/traefik-crd-27.0.201+up27.0.2.tgz
          - name: HELM_VERSION
          - name: TARGET_NAMESPACE
            value: kube-system
          - name: AUTH_PASS_CREDENTIALS
            value: "false"
          - name: INSECURE_SKIP_TLS_VERIFY
            value: "false"
          - name: PLAIN_HTTP
            value: "false"
          - name: NO_PROXY
            value: .svc,.cluster.local,10.42.0.0/16,10.43.0.0/16
          - name: FAILURE_POLICY
            value: reinstall
          image: rancher/klipper-helm:v0.9.3-build20241008
          imagePullPolicy: IfNotPresent
          name: helm
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /home/klipper-helm/.helm
            name: klipper-helm
          - mountPath: /home/klipper-helm/.cache
            name: klipper-cache
          - mountPath: /home/klipper-helm/.config
            name: klipper-config
          - mountPath: /tmp
            name: tmp
          - mountPath: /config
            name: values
          - mountPath: /chart
            name: content
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: OnFailure
        schedulerName: default-scheduler
        securityContext:
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: helm-traefik-crd
        serviceAccountName: helm-traefik-crd
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir:
            medium: Memory
          name: klipper-helm
        - emptyDir:
            medium: Memory
          name: klipper-cache
        - emptyDir:
            medium: Memory
          name: klipper-config
        - emptyDir:
            medium: Memory
          name: tmp
        - name: values
          secret:
            defaultMode: 420
            secretName: chart-values-traefik-crd
        - configMap:
            defaultMode: 420
            name: chart-content-traefik-crd
          name: content
  status:
    completionTime: "2025-02-02T14:26:32Z"
    conditions:
    - lastProbeTime: "2025-02-02T14:26:32Z"
      lastTransitionTime: "2025-02-02T14:26:32Z"
      message: Reached expected number of succeeded pods
      reason: CompletionsReached
      status: "True"
      type: SuccessCriteriaMet
    - lastProbeTime: "2025-02-02T14:26:32Z"
      lastTransitionTime: "2025-02-02T14:26:32Z"
      message: Reached expected number of succeeded pods
      reason: CompletionsReached
      status: "True"
      type: Complete
    ready: 0
    startTime: "2025-02-02T14:26:20Z"
    succeeded: 1
    terminating: 0
    uncountedTerminatedPods: {}
kind: List
metadata:
  resourceVersion: ""
